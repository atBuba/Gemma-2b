{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (4.38.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.42.4-py3-none-any.whl (9.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.3 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (0.32.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from transformers) (0.4.2)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Downloading tokenizers-0.19.1-cp39-cp39-macosx_11_0_arm64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: filelock in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from transformers) (2023.12.25)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2\n",
      "  Downloading huggingface_hub-0.24.0-py3-none-any.whl (419 kB)\n",
      "\u001b[K     |████████████████████████████████| 419 kB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: psutil in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from accelerate) (2.3.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.10.0)\n",
      "Requirement already satisfied: sympy in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: jinja2 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: networkx in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Installing collected packages: huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.21.3\n",
      "    Uninstalling huggingface-hub-0.21.3:\n",
      "      Successfully uninstalled huggingface-hub-0.21.3\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.2\n",
      "    Uninstalling tokenizers-0.15.2:\n",
      "      Successfully uninstalled tokenizers-0.15.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.38.2\n",
      "    Uninstalling transformers-4.38.2:\n",
      "      Successfully uninstalled transformers-4.38.2\n",
      "Successfully installed huggingface-hub-0.24.0 tokenizers-0.19.1 transformers-4.42.4\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<extra_id_0>System\n",
      "\n",
      "<extra_id_1>User\n",
      "Write a poem on NVIDIA in the style of Shakespeare\n",
      "<extra_id_1>Assistant\n",
      "\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='localhost', port=1424): Max retries exceeded with url: /generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x37cfbed30>: Failed to establish a new connection: [Errno 61] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connection.py:198\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 198\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:496\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 496\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connection.py:400\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[0;32m--> 400\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:1252\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1252\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:1012\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1012\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1015\u001b[0m \n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:952\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 952\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connection.py:238\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connection.py:213\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;66;03m# Audit hooks are only available in Python 3.8+\u001b[39;00m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x37cfbed30>: Failed to establish a new connection: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:847\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    845\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 847\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    850\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/util/retry.py:515\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    514\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    517\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=1424): Max retries exceeded with url: /generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x37cfbed30>: Failed to establish a new connection: [Errno 61] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m prompt \u001b[38;5;241m=\u001b[39m PROMPT_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(prompt\u001b[38;5;241m=\u001b[39mquestion)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(prompt)\n\u001b[0;32m---> 39\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgreedy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_BOS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_to_gen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepetition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m response \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;28mlen\u001b[39m(prompt):]\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<extra_id_1>\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "Cell \u001b[0;32mIn[23], line 25\u001b[0m, in \u001b[0;36mget_generation\u001b[0;34m(prompt, greedy, add_BOS, token_to_gen, min_tokens, temp, top_p, top_k, repetition, batch)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_generation\u001b[39m(prompt, greedy, add_BOS, token_to_gen, min_tokens, temp, top_p, top_k, repetition, batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     12\u001b[0m     data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentences\u001b[39m\u001b[38;5;124m\"\u001b[39m: [prompt] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batch \u001b[38;5;28;01melse\u001b[39;00m prompt,\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens_to_generate\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mint\u001b[39m(token_to_gen),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_strings\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|endoftext|>\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<extra_id_1>\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\x11\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<extra_id_1>User\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     24\u001b[0m     }\n\u001b[0;32m---> 25\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m \u001b[43mtext_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1424\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentences\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sentences[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batch \u001b[38;5;28;01melse\u001b[39;00m sentences\n",
      "Cell \u001b[0;32mIn[23], line 7\u001b[0m, in \u001b[0;36mtext_generation\u001b[0;34m(data, ip, port)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtext_generation\u001b[39m(data, ip\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocalhost\u001b[39m\u001b[38;5;124m'\u001b[39m, port\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m----> 7\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp://\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mip\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mport\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/generate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/api.py:130\u001b[0m, in \u001b[0;36mput\u001b[0;34m(url, data, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mput\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a PUT request.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/adapters.py:519\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    516\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='localhost', port=1424): Max retries exceeded with url: /generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x37cfbed30>: Failed to establish a new connection: [Errno 61] Connection refused'))"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "def text_generation(data, ip='localhost', port=None):\n",
    "    resp = requests.put(f'http://{ip}:{port}/generate', data=json.dumps(data), headers=headers)\n",
    "    return resp.json()\n",
    "\n",
    "\n",
    "def get_generation(prompt, greedy, add_BOS, token_to_gen, min_tokens, temp, top_p, top_k, repetition, batch=False):\n",
    "    data = {\n",
    "        \"sentences\": [prompt] if not batch else prompt,\n",
    "        \"tokens_to_generate\": int(token_to_gen),\n",
    "        \"temperature\": temp,\n",
    "        \"add_BOS\": add_BOS,\n",
    "        \"top_k\": top_k,\n",
    "        \"top_p\": top_p,\n",
    "        \"greedy\": greedy,\n",
    "        \"all_probs\": False,\n",
    "        \"repetition_penalty\": repetition,\n",
    "        \"min_tokens_to_generate\": int(min_tokens),\n",
    "        \"end_strings\": [\"<|endoftext|>\", \"<extra_id_1>\", \"\\x11\", \"<extra_id_1>User\"],\n",
    "    }\n",
    "    sentences = text_generation(data, port=1424)['sentences']\n",
    "    return sentences[0] if not batch else sentences\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"<extra_id_0>System\n",
    "\n",
    "<extra_id_1>User\n",
    "{prompt}\n",
    "<extra_id_1>Assistant\n",
    "\"\"\"\n",
    "\n",
    "question = \"Write a poem on NVIDIA in the style of Shakespeare\"\n",
    "prompt = PROMPT_TEMPLATE.format(prompt=question)\n",
    "print(prompt)\n",
    "\n",
    "response = get_generation(prompt, greedy=True, add_BOS=False, token_to_gen=1024, min_tokens=1, temp=1.0, top_p=1.0, top_k=0, repetition=1.0, batch=False)\n",
    "response = response[len(prompt):]\n",
    "if response.endswith(\"<extra_id_1>\"):\n",
    "    response = response[:-len(\"<extra_id_1>\")]\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/models/auto/auto_factory.py:561\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    560\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/modeling_utils.py:2945\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2942\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepSpeed Zero-3 is not compatible with `low_cpu_mem_usage=True` or with passing a `device_map`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2943\u001b[0m         )\n\u001b[1;32m   2944\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[0;32m-> 2945\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   2946\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2947\u001b[0m         )\n\u001b[1;32m   2949\u001b[0m \u001b[38;5;66;03m# handling bnb config from kwargs, remove after `load_in_{4/8}bit` deprecation.\u001b[39;00m\n\u001b[1;32m   2950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_in_4bit \u001b[38;5;129;01mor\u001b[39;00m load_in_8bit:\n",
      "\u001b[0;31mImportError\u001b[0m: Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/google/gemma-2-27b-it.\n401 Client Error. (Request ID: Root=1-669e2d51-03631904508353995c1eb6d6;3d251fa4-78ea-4431-802d-c79f5e529835)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-2-27b-it/resolve/main/config.json.\nAccess to model google/gemma-2-27b-it is restricted. You must be authenticated to access it.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/huggingface_hub/utils/_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/google/gemma-2-27b-it/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/utils/hub.py:402\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/huggingface_hub/utils/_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/huggingface_hub/file_download.py:1240\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/huggingface_hub/file_download.py:1347\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1346\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[0;32m-> 1347\u001b[0m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/huggingface_hub/file_download.py:1854\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[1;32m   1853\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[0;32m-> 1854\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[1;32m   1855\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1856\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/huggingface_hub/file_download.py:1751\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/huggingface_hub/file_download.py:1673\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1672\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1673\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1675\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1681\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1682\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/huggingface_hub/file_download.py:376\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 376\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/huggingface_hub/file_download.py:400\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    399\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 400\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/huggingface_hub/utils/_errors.py:321\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    318\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m     )\n\u001b[0;32m--> 321\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GatedRepoError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_message \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess to this resource is disabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mGatedRepoError\u001b[0m: 401 Client Error. (Request ID: Root=1-669e2d51-03631904508353995c1eb6d6;3d251fa4-78ea-4431-802d-c79f5e529835)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-2-27b-it/resolve/main/config.json.\nAccess to model google/gemma-2-27b-it is restricted. You must be authenticated to access it.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoogle/gemma-2-27b-it\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle/gemma-2-27b-it\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrite me a poem about Machine Learning.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/models/auto/tokenization_auto.py:846\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    844\u001b[0m         config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfor_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_dict)\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 846\u001b[0m         config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    849\u001b[0m config_tokenizer_class \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtokenizer_class\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mauto_map:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/models/auto/configuration_auto.py:965\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    963\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 965\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    967\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/configuration_utils.py:632\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 632\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[1;32m    634\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/configuration_utils.py:689\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 689\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/utils/hub.py:420\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_gated_repo:\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    421\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    422\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    423\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    426\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    430\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/google/gemma-2-27b-it.\n401 Client Error. (Request ID: Root=1-669e2d51-03631904508353995c1eb6d6;3d251fa4-78ea-4431-802d-c79f5e529835)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-2-27b-it/resolve/main/config.json.\nAccess to model google/gemma-2-27b-it is restricted. You must be authenticated to access it."
     ]
    }
   ],
   "source": [
    "# pip install accelerate\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-27b-it\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"google/gemma-2-27b-it\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "input_text = \"Write me a poem about Machine Learning.\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids)\n",
    "print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting cohere\n",
      "  Downloading cohere-5.6.1-py3-none-any.whl (178 kB)\n",
      "\u001b[K     |████████████████████████████████| 178 kB 178 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic>=1.9.2\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "\u001b[K     |████████████████████████████████| 423 kB 250 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting parameterized<0.10.0,>=0.9.0\n",
      "  Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from cohere) (4.10.0)\n",
      "Collecting httpx>=0.21.2\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 295 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from cohere) (2.31.0)\n",
      "Collecting fastavro<2.0.0,>=1.9.4\n",
      "  Downloading fastavro-1.9.5-cp39-cp39-macosx_10_9_universal2.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 507 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tokenizers<1,>=0.15 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from cohere) (0.19.1)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Collecting types-requests<3.0.0,>=2.0.0\n",
      "  Downloading types_requests-2.32.0.20240712-py3-none-any.whl (15 kB)\n",
      "Collecting boto3<2.0.0,>=1.34.0\n",
      "  Downloading boto3-1.34.145-py3-none-any.whl (139 kB)\n",
      "\u001b[K     |████████████████████████████████| 139 kB 320 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting s3transfer<0.11.0,>=0.10.0\n",
      "  Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 844 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting botocore<1.35.0,>=1.34.145\n",
      "  Downloading botocore-1.34.145-py3-none-any.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting urllib3<1.27,>=1.25.4\n",
      "  Downloading urllib3-1.26.19-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[K     |████████████████████████████████| 143 kB 581 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from botocore<1.35.0,>=1.34.145->boto3<2.0.0,>=1.34.0->cohere) (2.9.0.post0)\n",
      "Collecting anyio\n",
      "  Downloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "\u001b[K     |████████████████████████████████| 86 kB 969 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: idna in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from httpx>=0.21.2->cohere) (3.6)\n",
      "Collecting sniffio\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 979 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: certifi in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from httpx>=0.21.2->cohere) (2024.2.2)\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 752 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.20.1\n",
      "  Downloading pydantic_core-2.20.1-cp39-cp39-macosx_11_0_arm64.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 682 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.145->boto3<2.0.0,>=1.34.0->cohere) (1.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.0.0->cohere) (3.3.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from tokenizers<1,>=0.15->cohere) (0.24.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (23.2)\n",
      "Requirement already satisfied: filelock in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.2.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.66.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.1)\n",
      "Collecting types-requests<3.0.0,>=2.0.0\n",
      "  Downloading types_requests-2.32.0.20240622-py3-none-any.whl (15 kB)\n",
      "  Downloading types_requests-2.32.0.20240602-py3-none-any.whl (15 kB)\n",
      "  Downloading types_requests-2.32.0.20240523-py3-none-any.whl (15 kB)\n",
      "  Downloading types_requests-2.32.0.20240521-py3-none-any.whl (15 kB)\n",
      "  Downloading types_requests-2.31.0.20240406-py3-none-any.whl (15 kB)\n",
      "  Downloading types_requests-2.31.0.20240403-py3-none-any.whl (15 kB)\n",
      "  Downloading types_requests-2.31.0.20240402-py3-none-any.whl (15 kB)\n",
      "  Downloading types_requests-2.31.0.20240311-py3-none-any.whl (14 kB)\n",
      "  Downloading types_requests-2.31.0.20240310-py3-none-any.whl (14 kB)\n",
      "  Downloading types_requests-2.31.0.20240218-py3-none-any.whl (14 kB)\n",
      "  Downloading types_requests-2.31.0.20240125-py3-none-any.whl (14 kB)\n",
      "  Downloading types_requests-2.31.0.20240106-py3-none-any.whl (14 kB)\n",
      "  Downloading types_requests-2.31.0.20231231-py3-none-any.whl (14 kB)\n",
      "  Downloading types_requests-2.31.0.10-py3-none-any.whl (14 kB)\n",
      "  Downloading types_requests-2.31.0.9-py3-none-any.whl (14 kB)\n",
      "  Downloading types_requests-2.31.0.8-py3-none-any.whl (14 kB)\n",
      "  Downloading types_requests-2.31.0.7-py3-none-any.whl (14 kB)\n",
      "  Downloading types_requests-2.31.0.6-py3-none-any.whl (14 kB)\n",
      "Collecting types-urllib3\n",
      "  Downloading types_urllib3-1.26.25.14-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.21.2->cohere) (1.2.0)\n",
      "Installing collected packages: urllib3, jmespath, sniffio, h11, botocore, types-urllib3, s3transfer, pydantic-core, httpcore, anyio, annotated-types, types-requests, pydantic, parameterized, httpx-sse, httpx, fastavro, boto3, cohere\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.1\n",
      "    Uninstalling urllib3-2.2.1:\n",
      "      Successfully uninstalled urllib3-2.2.1\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.4.0 boto3-1.34.145 botocore-1.34.145 cohere-5.6.1 fastavro-1.9.5 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 httpx-sse-0.4.0 jmespath-1.0.1 parameterized-0.9.0 pydantic-2.8.2 pydantic-core-2.20.1 s3transfer-0.10.2 sniffio-1.3.1 types-requests-2.31.0.6 types-urllib3-1.26.25.14 urllib3-1.26.19\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcohere\u001b[39;00m\n\u001b[1;32m      3\u001b[0m co \u001b[38;5;241m=\u001b[39m cohere\u001b[38;5;241m.\u001b[39mClient(\n\u001b[1;32m      4\u001b[0m     api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYOUR_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m chat \u001b[38;5;241m=\u001b[39m \u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhello world!\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcommand\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(chat)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cohere/client.py:92\u001b[0m, in \u001b[0;36mexperimental_kwarg_decorator.<locals>._wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_kwarg(deprecated_kwarg, kwargs):\n\u001b[1;32m     88\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeprecated_kwarg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` parameter is an experimental feature and may change in future releases.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo suppress this warning, set `log_warning_experimental_features=False` when initializing the client.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m     )\n\u001b[0;32m---> 92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cohere/client.py:35\u001b[0m, in \u001b[0;36mvalidate_args.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs: typing\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: typing\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m     34\u001b[0m     check_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/cohere/base_client.py:884\u001b[0m, in \u001b[0;36mBaseCohere.chat\u001b[0;34m(self, message, model, preamble, chat_history, conversation_id, prompt_truncation, connectors, search_queries_only, documents, citation_quality, temperature, max_tokens, max_input_tokens, k, p, seed, stop_sequences, frequency_penalty, presence_penalty, raw_prompting, return_prompt, tools, tool_results, force_single_step, response_format, request_options)\u001b[0m\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnauthorizedError(\n\u001b[1;32m    880\u001b[0m         typing\u001b[38;5;241m.\u001b[39mcast(typing\u001b[38;5;241m.\u001b[39mAny, construct_type(type_\u001b[38;5;241m=\u001b[39mtyping\u001b[38;5;241m.\u001b[39mAny, object_\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mjson()))  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     )\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ForbiddenError(\n\u001b[0;32m--> 884\u001b[0m         typing\u001b[38;5;241m.\u001b[39mcast(typing\u001b[38;5;241m.\u001b[39mAny, construct_type(type_\u001b[38;5;241m=\u001b[39mtyping\u001b[38;5;241m.\u001b[39mAny, object_\u001b[38;5;241m=\u001b[39m\u001b[43m_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     )\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFoundError(\n\u001b[1;32m    888\u001b[0m         typing\u001b[38;5;241m.\u001b[39mcast(typing\u001b[38;5;241m.\u001b[39mAny, construct_type(type_\u001b[38;5;241m=\u001b[39mtyping\u001b[38;5;241m.\u001b[39mAny, object_\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mjson()))  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    889\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpx/_models.py:764\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjson\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: typing\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjsonlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "\n",
    "co = cohere.Client(\n",
    "    api_key=\"YOUR_API_KEY\",\n",
    ")\n",
    "\n",
    "chat = co.chat(\n",
    "    message=\"hello world!\",\n",
    "    model=\"command\"\n",
    ")\n",
    "\n",
    "print(chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: huggingface-hub in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (0.24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from huggingface-hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from huggingface-hub) (2.31.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from huggingface-hub) (23.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from huggingface-hub) (2024.2.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from huggingface-hub) (4.66.2)\n",
      "Requirement already satisfied: filelock in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from huggingface-hub) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from huggingface-hub) (4.10.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub) (3.6)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages/huggingface_hub/commands/download.py:132: FutureWarning: Ignoring --local-dir-use-symlinks. Downloading to a local directory does not use symlinks anymore.\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages/huggingface_hub/utils/_errors.py\", line 304, in hf_raise_for_status\n",
      "    response.raise_for_status()\n",
      "  File \"/Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages/requests/models.py\", line 1021, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/LiteLLMs/gemma-2b-GGUF/resolve/main/Q4_0/Q4_0-00001-of-00009.gguf\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nikitaklenskij/Library/Python/3.9/bin/huggingface-cli\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages/huggingface_hub/commands/huggingface_cli.py\", line 52, in main\n",
      "    service.run()\n",
      "  File \"/Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages/huggingface_hub/commands/download.py\", line 146, in run\n",
      "    print(self._download())  # Print path to downloaded files\n",
      "  File \"/Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages/huggingface_hub/commands/download.py\", line 159, in _download\n",
      "    return hf_hub_download(\n",
      "  File \"/Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages/huggingface_hub/utils/_deprecation.py\", line 101, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages/huggingface_hub/file_download.py\", line 1220, in hf_hub_download\n",
      "    return _hf_hub_download_to_local_dir(\n",
      "  File \"/Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages/huggingface_hub/file_download.py\", line 1447, in _hf_hub_download_to_local_dir\n",
      "    (url_to_download, etag, commit_hash, expected_size, head_call_error) = _get_metadata_or_catch_error(\n",
      "  File \"/Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages/huggingface_hub/file_download.py\", line 1751, in _get_metadata_or_catch_error\n",
      "    metadata = get_hf_file_metadata(\n",
      "  File \"/Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages/huggingface_hub/file_download.py\", line 1673, in get_hf_file_metadata\n",
      "    r = _request_wrapper(\n",
      "  File \"/Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages/huggingface_hub/file_download.py\", line 376, in _request_wrapper\n",
      "    response = _request_wrapper(\n",
      "  File \"/Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages/huggingface_hub/file_download.py\", line 400, in _request_wrapper\n",
      "    hf_raise_for_status(response)\n",
      "  File \"/Users/nikitaklenskij/Library/Python/3.9/lib/python/site-packages/huggingface_hub/utils/_errors.py\", line 315, in hf_raise_for_status\n",
      "    raise EntryNotFoundError(message, response) from e\n",
      "huggingface_hub.utils._errors.EntryNotFoundError: 404 Client Error. (Request ID: Root=1-66a0d226-7d111dcd624495c72ef55480;40bd191d-0ccf-4d7d-a391-77f0f2a6a2a9)\n",
      "\n",
      "Entry Not Found for url: https://huggingface.co/LiteLLMs/gemma-2b-GGUF/resolve/main/Q4_0/Q4_0-00001-of-00009.gguf.\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli download LiteLLMs/gemma-2b-GGUF Q4_0/Q4_0-00001-of-00009.gguf --local-dir . --local-dir-use-symlinks False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no such file or directory: ./main\n"
     ]
    }
   ],
   "source": [
    "!./main -ngl 35 -m Q4_0/Q4_0-00001-of-00009.gguf --color -c 8192 --temp 0.7 --repeat_penalty 1.1 -n -1 -p \"<PROMPT>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-cpp-python\n",
      "  Downloading llama_cpp_python-0.2.83.tar.gz (49.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /Users/nikitaklenskij/miniforge3/lib/python3.10/site-packages (from llama-cpp-python) (4.11.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /Users/nikitaklenskij/miniforge3/lib/python3.10/site-packages (from llama-cpp-python) (2.0.0)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in /Users/nikitaklenskij/miniforge3/lib/python3.10/site-packages (from llama-cpp-python) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nikitaklenskij/miniforge3/lib/python3.10/site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.83-cp310-cp310-macosx_14_0_arm64.whl size=2533990 sha256=ea677ce41d50a97f5baaf0531ef23be3ac5486da7f6d1fe86e41240cafc21e06\n",
      "  Stored in directory: /Users/nikitaklenskij/Library/Caches/pip/wheels/25/97/95/bd309ea454a04b3b46c2b6321749172cf68a0279d892f12534\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: diskcache, llama-cpp-python\n",
      "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.83\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_cpp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_cpp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Llama\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m llm \u001b[38;5;241m=\u001b[39m Llama(\n\u001b[1;32m      4\u001b[0m   model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./Q4_0/Q4_0-00001-of-00009.gguf\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Download the model file first\u001b[39;00m\n\u001b[1;32m      5\u001b[0m   n_ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32768\u001b[39m,  \u001b[38;5;66;03m# The max sequence length to use - note that longer sequence lengths require much more resources\u001b[39;00m\n\u001b[1;32m      6\u001b[0m   n_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,            \u001b[38;5;66;03m# The number of CPU threads to use, tailor to your system and the resulting performance\u001b[39;00m\n\u001b[1;32m      7\u001b[0m   n_gpu_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m35\u001b[39m         \u001b[38;5;66;03m# The number of layers to offload to GPU, if you have GPU acceleration available\u001b[39;00m\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama_cpp'"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
    "llm = Llama(\n",
    "  model_path=\"./Q4_0/Q4_0-00001-of-00009.gguf\",  # Download the model file first\n",
    "  n_ctx=32768,  # The max sequence length to use - note that longer sequence lengths require much more resources\n",
    "  n_threads=8,            # The number of CPU threads to use, tailor to your system and the resulting performance\n",
    "  n_gpu_layers=35         # The number of layers to offload to GPU, if you have GPU acceleration available\n",
    ")\n",
    "# Simple inference example\n",
    "output = llm(\n",
    "  \"<PROMPT>\", # Prompt\n",
    "  max_tokens=512,  # Generate up to 512 tokens\n",
    "  stop=[\"</s>\"],   # Example stop token - not necessarily correct for this specific model! Please check before using.\n",
    "  echo=True        # Whether to echo the prompt\n",
    ")\n",
    "# Chat Completion API\n",
    "llm = Llama(model_path=\"./Q4_0/Q4_0-00001-of-00009.gguf\", chat_format=\"llama-2\")  # Set chat_format according to the model you are using\n",
    "llm.create_chat_completion(\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a story writing assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a story about llamas.\"\n",
    "        }\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 1 files:   0%|                                   | 0/1 [00:00<?, ?it/s]Downloading 'gemma-2-9b-it-Q4_K_M.gguf' to '.cache/huggingface/download/gemma-2-9b-it-Q4_K_M.gguf.13b2a7b4115bbd0900162edcebe476da1ba1fc24e718e8b40d32f6e300f56dfe.incomplete'\n",
      "\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   0%|                    | 0.00/5.76G [00:00<?, ?B/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   0%|           | 10.5M/5.76G [00:00<06:11, 15.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   0%|           | 21.0M/5.76G [00:01<07:59, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   1%|           | 31.5M/5.76G [00:02<07:01, 13.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   1%|           | 41.9M/5.76G [00:03<07:20, 13.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   1%|           | 52.4M/5.76G [00:04<07:36, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   1%|           | 62.9M/5.76G [00:04<07:38, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   1%|▏          | 73.4M/5.76G [00:05<07:39, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   1%|▏          | 83.9M/5.76G [00:06<07:42, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   2%|▏          | 94.4M/5.76G [00:07<08:02, 11.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   2%|▏           | 105M/5.76G [00:08<07:30, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   2%|▏           | 115M/5.76G [00:09<07:36, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   2%|▎           | 126M/5.76G [00:10<07:37, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   2%|▎           | 136M/5.76G [00:10<07:42, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   3%|▎           | 147M/5.76G [00:11<07:50, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   3%|▎           | 157M/5.76G [00:12<07:33, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   3%|▎           | 168M/5.76G [00:13<08:18, 11.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   3%|▎           | 178M/5.76G [00:14<08:03, 11.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   3%|▍           | 189M/5.76G [00:15<07:51, 11.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   3%|▍           | 199M/5.76G [00:16<07:43, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   4%|▍           | 210M/5.76G [00:17<07:35, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   4%|▍           | 220M/5.76G [00:17<07:13, 12.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   4%|▍           | 231M/5.76G [00:18<07:38, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   4%|▌           | 241M/5.76G [00:19<07:10, 12.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   4%|▌           | 252M/5.76G [00:20<07:15, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   5%|▌           | 262M/5.76G [00:21<07:15, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   5%|▌           | 273M/5.76G [00:22<07:19, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   5%|▌           | 283M/5.76G [00:22<07:18, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   5%|▌           | 294M/5.76G [00:23<07:32, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   5%|▋           | 304M/5.76G [00:24<08:00, 11.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   5%|▋           | 315M/5.76G [00:25<07:27, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   6%|▋           | 325M/5.76G [00:26<07:10, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   6%|▋           | 336M/5.76G [00:27<07:11, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   6%|▋           | 346M/5.76G [00:28<07:21, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   6%|▋           | 357M/5.76G [00:29<08:04, 11.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   6%|▊           | 367M/5.76G [00:30<07:52, 11.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   7%|▊           | 377M/5.76G [00:30<07:19, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   7%|▊           | 388M/5.76G [00:31<07:02, 12.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   7%|▊           | 398M/5.76G [00:32<07:00, 12.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   7%|▊           | 409M/5.76G [00:33<07:14, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   7%|▊           | 419M/5.76G [00:34<07:20, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   7%|▉           | 430M/5.76G [00:35<07:33, 11.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   8%|▉           | 440M/5.76G [00:36<07:27, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   8%|▉           | 451M/5.76G [00:36<06:59, 12.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   8%|▉           | 461M/5.76G [00:37<07:12, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   8%|▉           | 472M/5.76G [00:38<06:57, 12.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   8%|█           | 482M/5.76G [00:39<07:03, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   9%|█           | 493M/5.76G [00:40<07:05, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   9%|█           | 503M/5.76G [00:41<07:41, 11.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   9%|█           | 514M/5.76G [00:42<07:29, 11.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   9%|█           | 524M/5.76G [00:42<07:11, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   9%|█           | 535M/5.76G [00:43<06:58, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:   9%|█▏          | 545M/5.76G [00:44<06:48, 12.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  10%|█▏          | 556M/5.76G [00:45<06:57, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  10%|█▏          | 566M/5.76G [00:46<07:01, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  10%|█▏          | 577M/5.76G [00:47<07:01, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  10%|█▏          | 587M/5.76G [00:47<07:05, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  10%|█▏          | 598M/5.76G [00:48<07:07, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  11%|█▎          | 608M/5.76G [00:49<06:59, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  11%|█▎          | 619M/5.76G [00:50<07:17, 11.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  11%|█▎          | 629M/5.76G [00:51<07:00, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  11%|█▎          | 640M/5.76G [00:52<07:27, 11.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  11%|█▎          | 650M/5.76G [00:53<06:57, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  11%|█▍          | 661M/5.76G [00:54<06:47, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  12%|█▍          | 671M/5.76G [00:54<07:00, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  12%|█▍          | 682M/5.76G [00:55<06:38, 12.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  12%|█▍          | 692M/5.76G [00:56<06:48, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  12%|█▍          | 703M/5.76G [00:57<06:50, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  12%|█▍          | 713M/5.76G [00:58<06:54, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  13%|█▌          | 724M/5.76G [00:59<06:58, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  13%|█▌          | 734M/5.76G [01:00<07:05, 11.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  13%|█▌          | 744M/5.76G [01:00<06:54, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  13%|█▌          | 755M/5.76G [01:01<07:06, 11.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  13%|█▌          | 765M/5.76G [01:02<06:41, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  13%|█▌          | 776M/5.76G [01:03<06:42, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  14%|█▋          | 786M/5.76G [01:04<06:44, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  14%|█▋          | 797M/5.76G [01:05<06:46, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  14%|█▋          | 807M/5.76G [01:06<06:41, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  14%|█▋          | 818M/5.76G [01:06<06:36, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  14%|█▋          | 828M/5.76G [01:07<06:50, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  15%|█▋          | 839M/5.76G [01:08<06:38, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  15%|█▊          | 849M/5.76G [01:09<06:39, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  15%|█▊          | 860M/5.76G [01:10<07:12, 11.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  15%|█▊          | 870M/5.76G [01:11<07:03, 11.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  15%|█▊          | 881M/5.76G [01:12<06:40, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  15%|█▊          | 891M/5.76G [01:12<06:19, 12.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  16%|█▉          | 902M/5.76G [01:13<06:24, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  16%|█▉          | 912M/5.76G [01:14<06:33, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  16%|█▉          | 923M/5.76G [01:15<06:27, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  16%|█▉          | 933M/5.76G [01:16<06:34, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  16%|█▉          | 944M/5.76G [01:17<06:32, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  17%|█▉          | 954M/5.76G [01:18<06:37, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  17%|██          | 965M/5.76G [01:18<06:34, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  17%|██          | 975M/5.76G [01:19<06:28, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  17%|██          | 986M/5.76G [01:20<06:56, 11.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  17%|██          | 996M/5.76G [01:21<06:49, 11.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  17%|█▉         | 1.01G/5.76G [01:22<06:21, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  18%|█▉         | 1.02G/5.76G [01:23<06:14, 12.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  18%|█▉         | 1.03G/5.76G [01:24<06:16, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  18%|█▉         | 1.04G/5.76G [01:24<06:26, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  18%|██         | 1.05G/5.76G [01:25<06:27, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  18%|██         | 1.06G/5.76G [01:26<06:25, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  19%|██         | 1.07G/5.76G [01:27<06:25, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  19%|██         | 1.08G/5.76G [01:28<06:28, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  19%|██         | 1.09G/5.76G [01:29<06:18, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  19%|██         | 1.10G/5.76G [01:30<06:26, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  19%|██         | 1.11G/5.76G [01:31<06:26, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  19%|██▏        | 1.12G/5.76G [01:32<06:36, 11.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  20%|██▏        | 1.13G/5.76G [01:32<06:35, 11.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  20%|██▏        | 1.14G/5.76G [01:33<06:16, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  20%|██▏        | 1.15G/5.76G [01:34<06:35, 11.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  20%|██▏        | 1.16G/5.76G [01:35<06:05, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  20%|██▏        | 1.17G/5.76G [01:36<06:52, 11.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  21%|██▎        | 1.18G/5.76G [01:37<06:45, 11.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  21%|██▎        | 1.20G/5.76G [01:38<06:41, 11.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  21%|██▎        | 1.21G/5.76G [01:39<06:26, 11.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  21%|██▎        | 1.22G/5.76G [01:39<05:49, 13.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  21%|██▎        | 1.23G/5.76G [01:40<05:36, 13.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  21%|██▎        | 1.24G/5.76G [01:41<05:41, 13.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  22%|██▍        | 1.25G/5.76G [01:42<05:57, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  22%|██▍        | 1.26G/5.76G [01:43<05:53, 12.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  22%|██▍        | 1.27G/5.76G [01:43<06:02, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  22%|██▍        | 1.28G/5.76G [01:44<05:55, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  22%|██▍        | 1.29G/5.76G [01:45<05:58, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  23%|██▍        | 1.30G/5.76G [01:46<05:59, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  23%|██▌        | 1.31G/5.76G [01:47<06:02, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  23%|██▌        | 1.32G/5.76G [01:48<06:10, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  23%|██▌        | 1.33G/5.76G [01:49<05:58, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  23%|██▌        | 1.34G/5.76G [01:49<05:58, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  23%|██▌        | 1.35G/5.76G [01:51<06:29, 11.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  24%|██▌        | 1.36G/5.76G [01:51<06:03, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  24%|██▌        | 1.37G/5.76G [01:52<06:11, 11.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  24%|██▋        | 1.38G/5.76G [01:53<05:51, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  24%|██▋        | 1.39G/5.76G [01:54<05:46, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  24%|██▋        | 1.41G/5.76G [01:55<05:49, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  25%|██▋        | 1.42G/5.76G [01:55<05:53, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  25%|██▋        | 1.43G/5.76G [01:56<05:55, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  25%|██▋        | 1.44G/5.76G [01:57<05:51, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  25%|██▊        | 1.45G/5.76G [01:58<05:58, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  25%|██▊        | 1.46G/5.76G [01:59<06:10, 11.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  25%|██▊        | 1.47G/5.76G [02:00<05:42, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  26%|██▊        | 1.48G/5.76G [02:01<06:10, 11.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  26%|██▊        | 1.49G/5.76G [02:02<06:08, 11.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  26%|██▊        | 1.50G/5.76G [02:02<05:43, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  26%|██▉        | 1.51G/5.76G [02:03<05:48, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  26%|██▉        | 1.52G/5.76G [02:04<05:52, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  27%|██▉        | 1.53G/5.76G [02:05<06:02, 11.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  27%|██▉        | 1.54G/5.76G [02:06<05:46, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  27%|██▉        | 1.55G/5.76G [02:07<05:36, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  27%|██▉        | 1.56G/5.76G [02:08<05:49, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  27%|███        | 1.57G/5.76G [02:08<05:20, 13.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  27%|███        | 1.58G/5.76G [02:09<05:28, 12.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  28%|███        | 1.59G/5.76G [02:10<05:55, 11.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  28%|███        | 1.60G/5.76G [02:11<05:49, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  28%|███        | 1.61G/5.76G [02:12<05:45, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  28%|███        | 1.63G/5.76G [02:13<05:33, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  28%|███        | 1.64G/5.76G [02:14<05:46, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  29%|███▏       | 1.65G/5.76G [02:14<05:31, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  29%|███▏       | 1.66G/5.76G [02:15<05:47, 11.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  29%|███▏       | 1.67G/5.76G [02:16<05:24, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  29%|███▏       | 1.68G/5.76G [02:17<05:26, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  29%|███▏       | 1.69G/5.76G [02:18<05:32, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  29%|███▏       | 1.70G/5.76G [02:19<05:37, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  30%|███▎       | 1.71G/5.76G [02:20<05:30, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  30%|███▎       | 1.72G/5.76G [02:20<05:26, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  30%|███▎       | 1.73G/5.76G [02:21<05:23, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  30%|███▎       | 1.74G/5.76G [02:22<05:48, 11.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  30%|███▎       | 1.75G/5.76G [02:23<05:14, 12.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  31%|███▎       | 1.76G/5.76G [02:24<05:47, 11.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  31%|███▍       | 1.77G/5.76G [02:25<05:22, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  31%|███▍       | 1.78G/5.76G [02:26<05:30, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  31%|███▍       | 1.79G/5.76G [02:26<05:13, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  31%|███▍       | 1.80G/5.76G [02:27<05:21, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  31%|███▍       | 1.81G/5.76G [02:28<05:20, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  32%|███▍       | 1.82G/5.76G [02:29<05:23, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  32%|███▌       | 1.84G/5.76G [02:30<05:27, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  32%|███▌       | 1.85G/5.76G [02:31<05:50, 11.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  32%|███▌       | 1.86G/5.76G [02:32<05:38, 11.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  32%|███▌       | 1.87G/5.76G [02:33<05:16, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  33%|███▌       | 1.88G/5.76G [02:33<05:00, 12.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  33%|███▌       | 1.89G/5.76G [02:34<05:06, 12.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  33%|███▌       | 1.90G/5.76G [02:35<05:16, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  33%|███▋       | 1.91G/5.76G [02:36<05:18, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  33%|███▋       | 1.92G/5.76G [02:37<05:16, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  33%|███▋       | 1.93G/5.76G [02:38<05:20, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  34%|███▋       | 1.94G/5.76G [02:39<05:14, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  34%|███▋       | 1.95G/5.76G [02:39<05:00, 12.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  34%|███▋       | 1.96G/5.76G [02:40<04:58, 12.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  34%|███▊       | 1.97G/5.76G [02:41<05:08, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  34%|███▊       | 1.98G/5.76G [02:42<05:07, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  35%|███▊       | 1.99G/5.76G [02:43<05:15, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  35%|███▊       | 2.00G/5.76G [02:44<05:16, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  35%|███▊       | 2.01G/5.76G [02:45<05:01, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  35%|███▊       | 2.02G/5.76G [02:45<04:56, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  35%|███▉       | 2.03G/5.76G [02:46<04:58, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  35%|███▉       | 2.04G/5.76G [02:47<04:58, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  36%|███▉       | 2.06G/5.76G [02:48<04:59, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  36%|███▉       | 2.07G/5.76G [02:49<05:07, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  36%|███▉       | 2.08G/5.76G [02:50<05:03, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  36%|███▉       | 2.09G/5.76G [02:51<05:08, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  36%|████       | 2.10G/5.76G [02:52<05:17, 11.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  37%|████       | 2.11G/5.76G [02:52<04:54, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  37%|████       | 2.12G/5.76G [02:53<04:46, 12.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  37%|████       | 2.13G/5.76G [02:54<04:55, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  37%|████       | 2.14G/5.76G [02:55<04:59, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  37%|████       | 2.15G/5.76G [02:56<05:08, 11.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  37%|████       | 2.16G/5.76G [02:57<04:59, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  38%|████▏      | 2.17G/5.76G [02:57<04:47, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  38%|████▏      | 2.18G/5.76G [02:58<04:55, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  38%|████▏      | 2.19G/5.76G [02:59<04:45, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  38%|████▏      | 2.20G/5.76G [03:00<04:46, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  38%|████▏      | 2.21G/5.76G [03:01<04:50, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  39%|████▏      | 2.22G/5.76G [03:02<05:19, 11.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  39%|████▎      | 2.23G/5.76G [03:03<05:10, 11.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  39%|████▎      | 2.24G/5.76G [03:04<04:47, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  39%|████▎      | 2.25G/5.76G [03:04<04:44, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  39%|████▎      | 2.26G/5.76G [03:05<04:41, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  39%|████▎      | 2.28G/5.76G [03:06<04:30, 12.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  40%|████▎      | 2.29G/5.76G [03:07<04:39, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  40%|████▍      | 2.30G/5.76G [03:08<04:34, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  40%|████▍      | 2.31G/5.76G [03:09<04:40, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  40%|████▍      | 2.32G/5.76G [03:10<04:42, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  40%|████▍      | 2.33G/5.76G [03:10<04:36, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  41%|████▍      | 2.34G/5.76G [03:11<04:36, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  41%|████▍      | 2.35G/5.76G [03:12<04:36, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  41%|████▌      | 2.36G/5.76G [03:13<04:40, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  41%|████▌      | 2.37G/5.76G [03:14<04:46, 11.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  41%|████▌      | 2.38G/5.76G [03:15<04:51, 11.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  41%|████▌      | 2.39G/5.76G [03:16<04:34, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  42%|████▌      | 2.40G/5.76G [03:17<04:53, 11.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  42%|████▌      | 2.41G/5.76G [03:17<04:27, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  42%|████▌      | 2.42G/5.76G [03:18<04:25, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  42%|████▋      | 2.43G/5.76G [03:19<04:30, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  42%|████▋      | 2.44G/5.76G [03:20<04:36, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  43%|████▋      | 2.45G/5.76G [03:21<04:40, 11.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  43%|████▋      | 2.46G/5.76G [03:22<04:39, 11.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  43%|████▋      | 2.47G/5.76G [03:22<04:20, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  43%|████▋      | 2.49G/5.76G [03:23<04:23, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  43%|████▊      | 2.50G/5.76G [03:24<04:20, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  44%|████▊      | 2.51G/5.76G [03:25<04:48, 11.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  44%|████▊      | 2.52G/5.76G [03:26<04:41, 11.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  44%|████▊      | 2.53G/5.76G [03:27<04:37, 11.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  44%|████▊      | 2.54G/5.76G [03:28<04:23, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  44%|████▊      | 2.55G/5.76G [03:28<04:04, 13.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  44%|████▉      | 2.56G/5.76G [03:29<04:11, 12.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  45%|████▉      | 2.57G/5.76G [03:30<04:12, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  45%|████▉      | 2.58G/5.76G [03:31<04:13, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  45%|████▉      | 2.59G/5.76G [03:32<04:19, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  45%|████▉      | 2.60G/5.76G [03:33<04:15, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  45%|████▉      | 2.61G/5.76G [03:34<04:15, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  46%|█████      | 2.62G/5.76G [03:34<04:12, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  46%|█████      | 2.63G/5.76G [03:35<04:17, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  46%|█████      | 2.64G/5.76G [03:36<04:13, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  46%|█████      | 2.65G/5.76G [03:37<04:34, 11.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  46%|█████      | 2.66G/5.76G [03:38<04:19, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  46%|█████      | 2.67G/5.76G [03:39<04:26, 11.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  47%|█████▏     | 2.68G/5.76G [03:40<04:24, 11.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  47%|█████▏     | 2.69G/5.76G [03:41<04:03, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  47%|█████▏     | 2.71G/5.76G [03:41<04:06, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  47%|█████▏     | 2.72G/5.76G [03:42<04:06, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  47%|█████▏     | 2.73G/5.76G [03:43<04:09, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  48%|█████▏     | 2.74G/5.76G [03:44<04:06, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  48%|█████▏     | 2.75G/5.76G [03:45<04:05, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  48%|█████▎     | 2.76G/5.76G [03:46<04:12, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  48%|█████▎     | 2.77G/5.76G [03:46<03:54, 12.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  48%|█████▎     | 2.78G/5.76G [03:47<03:58, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  48%|█████▎     | 2.79G/5.76G [03:48<04:01, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  49%|█████▎     | 2.80G/5.76G [03:49<04:02, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  49%|█████▎     | 2.81G/5.76G [03:50<04:05, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  49%|█████▍     | 2.82G/5.76G [03:51<03:57, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  49%|█████▍     | 2.83G/5.76G [03:52<04:00, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  49%|█████▍     | 2.84G/5.76G [03:53<03:53, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  50%|█████▍     | 2.85G/5.76G [03:54<04:16, 11.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  50%|█████▍     | 2.86G/5.76G [03:54<04:09, 11.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  50%|█████▍     | 2.87G/5.76G [03:55<04:03, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  50%|█████▌     | 2.88G/5.76G [03:56<03:58, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  50%|█████▌     | 2.89G/5.76G [03:57<03:47, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  50%|█████▌     | 2.90G/5.76G [03:58<03:43, 12.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  51%|█████▌     | 2.92G/5.76G [03:59<03:49, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  51%|█████▌     | 2.93G/5.76G [03:59<03:45, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  51%|█████▌     | 2.94G/5.76G [04:00<03:49, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  51%|█████▋     | 2.95G/5.76G [04:01<03:51, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  51%|█████▋     | 2.96G/5.76G [04:02<03:51, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  52%|█████▋     | 2.97G/5.76G [04:03<03:46, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  52%|█████▋     | 2.98G/5.76G [04:04<04:11, 11.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  52%|█████▋     | 2.99G/5.76G [04:05<03:36, 12.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  52%|█████▋     | 3.00G/5.76G [04:06<03:47, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  52%|█████▋     | 3.01G/5.76G [04:06<03:35, 12.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  52%|█████▊     | 3.02G/5.76G [04:07<03:40, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  53%|█████▊     | 3.03G/5.76G [04:08<03:42, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  53%|█████▊     | 3.04G/5.76G [04:09<03:39, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  53%|█████▊     | 3.05G/5.76G [04:10<03:40, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  53%|█████▊     | 3.06G/5.76G [04:11<03:42, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  53%|█████▊     | 3.07G/5.76G [04:11<03:39, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  54%|█████▉     | 3.08G/5.76G [04:12<03:40, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  54%|█████▉     | 3.09G/5.76G [04:13<03:53, 11.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  54%|█████▉     | 3.10G/5.76G [04:14<03:50, 11.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  54%|█████▉     | 3.11G/5.76G [04:15<03:41, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  54%|█████▉     | 3.12G/5.76G [04:16<03:38, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  54%|█████▉     | 3.14G/5.76G [04:17<03:31, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  55%|██████     | 3.15G/5.76G [04:18<03:40, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  55%|██████     | 3.16G/5.76G [04:18<03:33, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  55%|██████     | 3.17G/5.76G [04:19<03:22, 12.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  55%|██████     | 3.18G/5.76G [04:20<03:22, 12.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  55%|██████     | 3.19G/5.76G [04:21<03:26, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  56%|██████     | 3.20G/5.76G [04:22<03:31, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  56%|██████▏    | 3.21G/5.76G [04:23<03:24, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  56%|██████▏    | 3.22G/5.76G [04:24<03:27, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  56%|██████▏    | 3.23G/5.76G [04:24<03:23, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  56%|██████▏    | 3.24G/5.76G [04:25<03:24, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  56%|██████▏    | 3.25G/5.76G [04:26<03:24, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  57%|██████▏    | 3.26G/5.76G [04:27<03:29, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  57%|██████▏    | 3.27G/5.76G [04:28<03:21, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  57%|██████▎    | 3.28G/5.76G [04:29<03:23, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  57%|██████▎    | 3.29G/5.76G [04:30<03:23, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  57%|██████▎    | 3.30G/5.76G [04:30<03:19, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  58%|██████▎    | 3.31G/5.76G [04:31<03:19, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  58%|██████▎    | 3.32G/5.76G [04:32<03:22, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  58%|██████▎    | 3.33G/5.76G [04:33<03:17, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  58%|██████▍    | 3.34G/5.76G [04:34<03:17, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  58%|██████▍    | 3.36G/5.76G [04:35<03:16, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  58%|██████▍    | 3.37G/5.76G [04:36<03:20, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  59%|██████▍    | 3.38G/5.76G [04:36<03:17, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  59%|██████▍    | 3.39G/5.76G [04:37<03:25, 11.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  59%|██████▍    | 3.40G/5.76G [04:38<03:08, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  59%|██████▌    | 3.41G/5.76G [04:39<03:27, 11.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  59%|██████▌    | 3.42G/5.76G [04:40<03:06, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  60%|██████▌    | 3.43G/5.76G [04:41<03:06, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  60%|██████▌    | 3.44G/5.76G [04:42<03:05, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  60%|██████▌    | 3.45G/5.76G [04:42<03:06, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  60%|██████▌    | 3.46G/5.76G [04:43<03:06, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  60%|██████▋    | 3.47G/5.76G [04:44<03:08, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  60%|██████▋    | 3.48G/5.76G [04:45<03:10, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  61%|██████▋    | 3.49G/5.76G [04:46<03:07, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  61%|██████▋    | 3.50G/5.76G [04:47<03:09, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  61%|██████▋    | 3.51G/5.76G [04:48<03:05, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  61%|██████▋    | 3.52G/5.76G [04:49<03:05, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  61%|██████▋    | 3.53G/5.76G [04:49<03:03, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  62%|██████▊    | 3.54G/5.76G [04:50<03:04, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  62%|██████▊    | 3.55G/5.76G [04:51<02:57, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  62%|██████▊    | 3.57G/5.76G [04:52<03:02, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  62%|██████▊    | 3.58G/5.76G [04:53<03:03, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  62%|██████▊    | 3.59G/5.76G [04:54<03:07, 11.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  62%|██████▊    | 3.60G/5.76G [04:54<02:48, 12.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  63%|██████▉    | 3.61G/5.76G [04:55<02:54, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  63%|██████▉    | 3.62G/5.76G [04:56<02:54, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  63%|██████▉    | 3.63G/5.76G [04:57<02:50, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  63%|██████▉    | 3.64G/5.76G [04:58<02:49, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  63%|██████▉    | 3.65G/5.76G [04:59<02:55, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  64%|██████▉    | 3.66G/5.76G [05:00<02:49, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  64%|███████    | 3.67G/5.76G [05:01<02:52, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  64%|███████    | 3.68G/5.76G [05:01<02:56, 11.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  64%|███████    | 3.69G/5.76G [05:02<02:46, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  64%|███████    | 3.70G/5.76G [05:03<02:44, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  64%|███████    | 3.71G/5.76G [05:04<02:50, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  65%|███████    | 3.72G/5.76G [05:05<02:45, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  65%|███████▏   | 3.73G/5.76G [05:06<02:44, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  65%|███████▏   | 3.74G/5.76G [05:07<02:47, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  65%|███████▏   | 3.75G/5.76G [05:07<02:42, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  65%|███████▏   | 3.76G/5.76G [05:08<02:41, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  66%|███████▏   | 3.77G/5.76G [05:09<02:44, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  66%|███████▏   | 3.79G/5.76G [05:10<02:41, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  66%|███████▏   | 3.80G/5.76G [05:11<02:53, 11.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  66%|███████▎   | 3.81G/5.76G [05:12<02:41, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  66%|███████▎   | 3.82G/5.76G [05:13<02:38, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  66%|███████▎   | 3.83G/5.76G [05:13<02:34, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  67%|███████▎   | 3.84G/5.76G [05:14<02:34, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  67%|███████▎   | 3.85G/5.76G [05:15<02:36, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  67%|███████▎   | 3.86G/5.76G [05:16<02:35, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  67%|███████▍   | 3.87G/5.76G [05:17<02:36, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  67%|███████▍   | 3.88G/5.76G [05:18<02:40, 11.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  68%|███████▍   | 3.89G/5.76G [05:19<02:33, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  68%|███████▍   | 3.90G/5.76G [05:20<02:33, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  68%|███████▍   | 3.91G/5.76G [05:20<02:29, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  68%|███████▍   | 3.92G/5.76G [05:21<02:27, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  68%|███████▌   | 3.93G/5.76G [05:22<02:29, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  68%|███████▌   | 3.94G/5.76G [05:23<02:28, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  69%|███████▌   | 3.95G/5.76G [05:24<02:26, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  69%|███████▌   | 3.96G/5.76G [05:25<02:36, 11.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  69%|███████▌   | 3.97G/5.76G [05:26<02:32, 11.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  69%|███████▌   | 3.98G/5.76G [05:26<02:26, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  69%|███████▋   | 4.00G/5.76G [05:27<02:19, 12.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  70%|███████▋   | 4.01G/5.76G [05:28<02:30, 11.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  70%|███████▋   | 4.02G/5.76G [05:29<02:16, 12.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  70%|███████▋   | 4.03G/5.76G [05:30<02:17, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  70%|███████▋   | 4.04G/5.76G [05:31<02:18, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  70%|███████▋   | 4.05G/5.76G [05:31<02:18, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  70%|███████▋   | 4.06G/5.76G [05:32<02:17, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  71%|███████▊   | 4.07G/5.76G [05:33<02:21, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  71%|███████▊   | 4.08G/5.76G [05:34<02:16, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  71%|███████▊   | 4.09G/5.76G [05:35<02:15, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  71%|███████▊   | 4.10G/5.76G [05:36<02:17, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  71%|███████▊   | 4.11G/5.76G [05:37<02:27, 11.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  72%|███████▊   | 4.12G/5.76G [05:38<02:17, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  72%|███████▉   | 4.13G/5.76G [05:38<02:10, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  72%|███████▉   | 4.14G/5.76G [05:39<02:11, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  72%|███████▉   | 4.15G/5.76G [05:40<02:08, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  72%|███████▉   | 4.16G/5.76G [05:41<02:10, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  72%|███████▉   | 4.17G/5.76G [05:42<02:09, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  73%|███████▉   | 4.18G/5.76G [05:43<02:08, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  73%|████████   | 4.19G/5.76G [05:44<02:06, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  73%|████████   | 4.20G/5.76G [05:44<02:05, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  73%|████████   | 4.22G/5.76G [05:45<02:05, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  73%|████████   | 4.23G/5.76G [05:46<02:10, 11.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  74%|████████   | 4.24G/5.76G [05:47<02:03, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  74%|████████   | 4.25G/5.76G [05:48<02:02, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  74%|████████▏  | 4.26G/5.76G [05:49<02:02, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  74%|████████▏  | 4.27G/5.76G [05:50<02:08, 11.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  74%|████████▏  | 4.28G/5.76G [05:50<02:00, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  74%|████████▏  | 4.29G/5.76G [05:51<01:58, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  75%|████████▏  | 4.30G/5.76G [05:52<02:04, 11.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  75%|████████▏  | 4.31G/5.76G [05:53<01:55, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  75%|████████▏  | 4.32G/5.76G [05:54<01:57, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  75%|████████▎  | 4.33G/5.76G [05:55<01:58, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  75%|████████▎  | 4.34G/5.76G [05:56<01:54, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  76%|████████▎  | 4.35G/5.76G [05:56<01:54, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  76%|████████▎  | 4.36G/5.76G [05:57<01:54, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  76%|████████▎  | 4.37G/5.76G [05:58<01:56, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  76%|████████▎  | 4.38G/5.76G [05:59<01:51, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  76%|████████▍  | 4.39G/5.76G [06:00<01:51, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  76%|████████▍  | 4.40G/5.76G [06:01<01:50, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  77%|████████▍  | 4.41G/5.76G [06:02<01:55, 11.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  77%|████████▍  | 4.42G/5.76G [06:02<01:47, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  77%|████████▍  | 4.44G/5.76G [06:03<01:47, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  77%|████████▍  | 4.45G/5.76G [06:04<01:49, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  77%|████████▌  | 4.46G/5.76G [06:05<01:46, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  78%|████████▌  | 4.47G/5.76G [06:06<01:45, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  78%|████████▌  | 4.48G/5.76G [06:07<01:44, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  78%|████████▌  | 4.49G/5.76G [06:08<01:46, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  78%|████████▌  | 4.50G/5.76G [06:08<01:42, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  78%|████████▌  | 4.51G/5.76G [06:09<01:42, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  78%|████████▋  | 4.52G/5.76G [06:10<01:40, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  79%|████████▋  | 4.53G/5.76G [06:11<01:43, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  79%|████████▋  | 4.54G/5.76G [06:12<01:45, 11.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  79%|████████▋  | 4.55G/5.76G [06:13<01:37, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  79%|████████▋  | 4.56G/5.76G [06:14<01:41, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  79%|████████▋  | 4.57G/5.76G [06:15<01:37, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  80%|████████▋  | 4.58G/5.76G [06:15<01:37, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  80%|████████▊  | 4.59G/5.76G [06:16<01:35, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  80%|████████▊  | 4.60G/5.76G [06:17<01:35, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  80%|████████▊  | 4.61G/5.76G [06:18<01:32, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  80%|████████▊  | 4.62G/5.76G [06:19<01:32, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  80%|████████▊  | 4.63G/5.76G [06:20<01:35, 11.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  81%|████████▊  | 4.65G/5.76G [06:21<01:34, 11.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  81%|████████▉  | 4.66G/5.76G [06:22<01:32, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  81%|████████▉  | 4.67G/5.76G [06:22<01:32, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  81%|████████▉  | 4.68G/5.76G [06:23<01:31, 11.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  81%|████████▉  | 4.69G/5.76G [06:24<01:28, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  82%|████████▉  | 4.70G/5.76G [06:25<01:23, 12.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  82%|████████▉  | 4.71G/5.76G [06:26<01:24, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  82%|█████████  | 4.72G/5.76G [06:27<01:22, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  82%|█████████  | 4.73G/5.76G [06:27<01:22, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  82%|█████████  | 4.74G/5.76G [06:28<01:22, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  82%|█████████  | 4.75G/5.76G [06:29<01:22, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  83%|█████████  | 4.76G/5.76G [06:30<01:24, 11.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  83%|█████████  | 4.77G/5.76G [06:31<01:21, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  83%|█████████▏ | 4.78G/5.76G [06:32<01:21, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  83%|█████████▏ | 4.79G/5.76G [06:33<01:23, 11.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  83%|█████████▏ | 4.80G/5.76G [06:34<01:17, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  84%|█████████▏ | 4.81G/5.76G [06:34<01:18, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  84%|█████████▏ | 4.82G/5.76G [06:35<01:13, 12.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  84%|█████████▏ | 4.83G/5.76G [06:36<01:13, 12.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  84%|█████████▏ | 4.84G/5.76G [06:37<01:13, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  84%|█████████▎ | 4.85G/5.76G [06:38<01:14, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  84%|█████████▎ | 4.87G/5.76G [06:39<01:13, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  85%|█████████▎ | 4.88G/5.76G [06:40<01:15, 11.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  85%|█████████▎ | 4.89G/5.76G [06:40<01:10, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  85%|█████████▎ | 4.90G/5.76G [06:41<01:11, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  85%|█████████▎ | 4.91G/5.76G [06:42<01:13, 11.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  85%|█████████▍ | 4.92G/5.76G [06:43<01:12, 11.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  86%|█████████▍ | 4.93G/5.76G [06:44<01:06, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  86%|█████████▍ | 4.94G/5.76G [06:45<01:05, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  86%|█████████▍ | 4.95G/5.76G [06:46<01:05, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  86%|█████████▍ | 4.96G/5.76G [06:46<01:06, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  86%|█████████▍ | 4.97G/5.76G [06:47<01:05, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  86%|█████████▌ | 4.98G/5.76G [06:48<01:03, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  87%|█████████▌ | 4.99G/5.76G [06:49<01:06, 11.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  87%|█████████▌ | 5.00G/5.76G [06:50<01:01, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  87%|█████████▌ | 5.01G/5.76G [06:51<01:02, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  87%|█████████▌ | 5.02G/5.76G [06:52<01:02, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  87%|█████████▌ | 5.03G/5.76G [06:53<01:00, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  88%|█████████▋ | 5.04G/5.76G [06:53<00:59, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  88%|█████████▋ | 5.05G/5.76G [06:54<00:54, 12.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  88%|█████████▋ | 5.06G/5.76G [06:55<00:54, 12.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  88%|█████████▋ | 5.08G/5.76G [06:56<00:55, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  88%|█████████▋ | 5.09G/5.76G [06:57<00:54, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  88%|█████████▋ | 5.10G/5.76G [06:58<00:55, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  89%|█████████▊ | 5.11G/5.76G [06:59<00:58, 11.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  89%|█████████▊ | 5.12G/5.76G [07:00<00:55, 11.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  89%|█████████▊ | 5.13G/5.76G [07:00<00:51, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  89%|█████████▊ | 5.14G/5.76G [07:01<00:47, 13.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  89%|█████████▊ | 5.15G/5.76G [07:02<00:49, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  90%|█████████▊ | 5.16G/5.76G [07:03<00:47, 12.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  90%|█████████▊ | 5.17G/5.76G [07:04<00:47, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  90%|█████████▉ | 5.18G/5.76G [07:05<00:47, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  90%|█████████▉ | 5.19G/5.76G [07:05<00:46, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  90%|█████████▉ | 5.20G/5.76G [07:06<00:45, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  90%|█████████▉ | 5.21G/5.76G [07:07<00:44, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  91%|█████████▉ | 5.22G/5.76G [07:08<00:46, 11.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  91%|█████████▉ | 5.23G/5.76G [07:09<00:42, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  91%|██████████ | 5.24G/5.76G [07:10<00:42, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  91%|██████████ | 5.25G/5.76G [07:10<00:40, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  91%|██████████ | 5.26G/5.76G [07:11<00:40, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  92%|██████████ | 5.27G/5.76G [07:12<00:39, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  92%|██████████ | 5.28G/5.76G [07:13<00:38, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  92%|██████████ | 5.30G/5.76G [07:14<00:38, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  92%|██████████▏| 5.31G/5.76G [07:15<00:37, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  92%|██████████▏| 5.32G/5.76G [07:16<00:37, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  92%|██████████▏| 5.33G/5.76G [07:17<00:34, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  93%|██████████▏| 5.34G/5.76G [07:17<00:34, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  93%|██████████▏| 5.35G/5.76G [07:18<00:35, 11.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  93%|██████████▏| 5.36G/5.76G [07:19<00:32, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  93%|██████████▎| 5.37G/5.76G [07:20<00:32, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  93%|██████████▎| 5.38G/5.76G [07:21<00:31, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  94%|██████████▎| 5.39G/5.76G [07:22<00:29, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  94%|██████████▎| 5.40G/5.76G [07:23<00:29, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  94%|██████████▎| 5.41G/5.76G [07:23<00:29, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  94%|██████████▎| 5.42G/5.76G [07:24<00:28, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  94%|██████████▎| 5.43G/5.76G [07:25<00:27, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  94%|██████████▍| 5.44G/5.76G [07:26<00:26, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  95%|██████████▍| 5.45G/5.76G [07:27<00:24, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  95%|██████████▍| 5.46G/5.76G [07:28<00:24, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  95%|██████████▍| 5.47G/5.76G [07:29<00:23, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  95%|██████████▍| 5.48G/5.76G [07:30<00:23, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  95%|██████████▍| 5.49G/5.76G [07:30<00:22, 11.8MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  96%|██████████▌| 5.51G/5.76G [07:31<00:20, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  96%|██████████▌| 5.52G/5.76G [07:32<00:20, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  96%|██████████▌| 5.53G/5.76G [07:33<00:18, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  96%|██████████▌| 5.54G/5.76G [07:34<00:19, 11.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  96%|██████████▌| 5.55G/5.76G [07:35<00:18, 11.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  96%|██████████▌| 5.56G/5.76G [07:36<00:16, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  97%|██████████▋| 5.57G/5.76G [07:36<00:15, 12.7MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  97%|██████████▋| 5.58G/5.76G [07:37<00:14, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  97%|██████████▋| 5.59G/5.76G [07:38<00:14, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  97%|██████████▋| 5.60G/5.76G [07:39<00:13, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  97%|██████████▋| 5.61G/5.76G [07:40<00:12, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  98%|██████████▋| 5.62G/5.76G [07:41<00:11, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  98%|██████████▊| 5.63G/5.76G [07:42<00:10, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  98%|██████████▊| 5.64G/5.76G [07:42<00:09, 12.3MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  98%|██████████▊| 5.65G/5.76G [07:43<00:09, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  98%|██████████▊| 5.66G/5.76G [07:44<00:08, 11.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  98%|██████████▊| 5.67G/5.76G [07:45<00:07, 12.0MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  99%|██████████▊| 5.68G/5.76G [07:46<00:06, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  99%|██████████▊| 5.69G/5.76G [07:47<00:05, 12.9MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  99%|██████████▉| 5.70G/5.76G [07:48<00:04, 12.1MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  99%|██████████▉| 5.71G/5.76G [07:48<00:03, 12.6MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf:  99%|██████████▉| 5.73G/5.76G [07:49<00:02, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf: 100%|██████████▉| 5.74G/5.76G [07:50<00:02, 12.5MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf: 100%|██████████▉| 5.75G/5.76G [07:51<00:01, 12.4MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf: 100%|██████████▉| 5.76G/5.76G [07:52<00:00, 12.2MB/s]\u001b[A\n",
      "gemma-2-9b-it-Q4_K_M.gguf: 100%|███████████| 5.76G/5.76G [07:52<00:00, 12.2MB/s]\u001b[A\n",
      "Download complete. Moving file to gemma-2-9b-it-Q4_K_M.gguf\n",
      "Fetching 1 files: 100%|██████████████████████████| 1/1 [07:54<00:00, 474.17s/it]\n",
      "/Users/nikitaklenskij/Documents/programs/ШИФТЛАБ\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli download bartowski/gemma-2-9b-it-GGUF --include \"gemma-2-9b-it-Q4_K_M.gguf\" --local-dir ./\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "from rich import print\n",
    "\n",
    "# Укажите путь к скачанной модели\n",
    "model_path = \"gemma-2-9b-it-Q4_K_M.gguf\"\n",
    "\n",
    "# Загрузка модели\n",
    "model = Llama(model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5119.26 ms\n",
      "llama_print_timings:      sample time =       1.83 ms /    16 runs   (    0.11 ms per token,  8733.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5406.75 ms /    14 tokens (  386.20 ms per token,     2.59 tokens per second)\n",
      "llama_print_timings:        eval time =   90921.79 ms /    15 runs   ( 6061.45 ms per token,     0.16 tokens per second)\n",
      "llama_print_timings:       total time =   96370.36 ms /    29 tokens\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "**Тема:**  Передача работы по веб-сайту\n",
       "\n",
       "**За\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "**Тема:**  Передача работы по веб-сайту\n",
       "\n",
       "**За\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Пример ввода\n",
    "input_text = \"Напиши мне диалог между заказчиком и исполнителем используя сарказм\"\n",
    "\n",
    "# Генерация ответа\n",
    "output = model(input_text)\n",
    "\n",
    "# Извлечение сгенерированного текста\n",
    "generated = output['choices'][0]['text']\n",
    "\n",
    "# Вывод ответа с использованием rich\n",
    "print(generated_poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": ".cache/huggingface/download does not appear to have a file named config.json. Checkout 'https://huggingface.co/.cache/huggingface/download/tree/None' for available files.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\u001b[0;32m----> 2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.cache/huggingface/download\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/models/auto/tokenization_auto.py:846\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    844\u001b[0m         config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfor_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_dict)\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 846\u001b[0m         config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    849\u001b[0m config_tokenizer_class \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtokenizer_class\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mauto_map:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/models/auto/configuration_auto.py:965\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    963\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 965\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    967\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/configuration_utils.py:632\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 632\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[1;32m    634\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/configuration_utils.py:689\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 689\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/utils/hub.py:373\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(resolved_file):\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _raise_exceptions_for_missing_entries:\n\u001b[0;32m--> 373\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    374\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not appear to have a file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Checkout \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    375\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/tree/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    376\u001b[0m         )\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: .cache/huggingface/download does not appear to have a file named config.json. Checkout 'https://huggingface.co/.cache/huggingface/download/tree/None' for available files."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "tokenizer = AutoTokenizer.from_pretrained(\".cache/huggingface/download\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 33 key-value pairs and 464 tensors from gemma-2-9b-it-Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = gemma2\n",
      "llama_model_loader: - kv   1:                               general.name str              = gemma-2-9b-it\n",
      "llama_model_loader: - kv   2:                      gemma2.context_length u32              = 8192\n",
      "llama_model_loader: - kv   3:                    gemma2.embedding_length u32              = 3584\n",
      "llama_model_loader: - kv   4:                         gemma2.block_count u32              = 42\n",
      "llama_model_loader: - kv   5:                 gemma2.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                gemma2.attention.head_count u32              = 16\n",
      "llama_model_loader: - kv   7:             gemma2.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   8:    gemma2.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv   9:                gemma2.attention.key_length u32              = 256\n",
      "llama_model_loader: - kv  10:              gemma2.attention.value_length u32              = 256\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:              gemma2.attn_logit_softcapping f32              = 50.000000\n",
      "llama_model_loader: - kv  13:             gemma2.final_logit_softcapping f32              = 30.000000\n",
      "llama_model_loader: - kv  14:            gemma2.attention.sliding_window u32              = 4096\n",
      "llama_model_loader: - kv  15:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  16:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.tokens arr[str,256000]  = [\"<pad>\", \"<eos>\", \"<bos>\", \"<unk>\", ...\n",
      "llama_model_loader: - kv  18:                      tokenizer.ggml.scores arr[f32,256000]  = [-1000.000000, -1000.000000, -1000.00...\n",
      "llama_model_loader: - kv  19:                  tokenizer.ggml.token_type arr[i32,256000]  = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\n",
      "llama_model_loader: - kv  20:                tokenizer.ggml.bos_token_id u32              = 2\n",
      "llama_model_loader: - kv  21:                tokenizer.ggml.eos_token_id u32              = 1\n",
      "llama_model_loader: - kv  22:            tokenizer.ggml.unknown_token_id u32              = 3\n",
      "llama_model_loader: - kv  23:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  24:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  25:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  26:                    tokenizer.chat_template str              = {{ bos_token }}{% if messages[0]['rol...\n",
      "llama_model_loader: - kv  27:            tokenizer.ggml.add_space_prefix bool             = false\n",
      "llama_model_loader: - kv  28:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  29:                      quantize.imatrix.file str              = /models_out/gemma-2-9b-it-GGUF/gemma-...\n",
      "llama_model_loader: - kv  30:                   quantize.imatrix.dataset str              = /training_dir/calibration_datav3.txt\n",
      "llama_model_loader: - kv  31:             quantize.imatrix.entries_count i32              = 294\n",
      "llama_model_loader: - kv  32:              quantize.imatrix.chunks_count i32              = 128\n",
      "llama_model_loader: - type  f32:  169 tensors\n",
      "llama_model_loader: - type q4_K:  252 tensors\n",
      "llama_model_loader: - type q6_K:   43 tensors\n",
      "llm_load_vocab: special tokens cache size = 217\n",
      "llm_load_vocab: token to piece cache size = 1.6014 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = gemma2\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 256000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 3584\n",
      "llm_load_print_meta: n_layer          = 42\n",
      "llm_load_print_meta: n_head           = 16\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 256\n",
      "llm_load_print_meta: n_swa            = 4096\n",
      "llm_load_print_meta: n_embd_head_k    = 256\n",
      "llm_load_print_meta: n_embd_head_v    = 256\n",
      "llm_load_print_meta: n_gqa            = 2\n",
      "llm_load_print_meta: n_embd_k_gqa     = 2048\n",
      "llm_load_print_meta: n_embd_v_gqa     = 2048\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 2\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 9B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 9.24 B\n",
      "llm_load_print_meta: model size       = 5.36 GiB (4.98 BPW) \n",
      "llm_load_print_meta: general.name     = gemma-2-9b-it\n",
      "llm_load_print_meta: BOS token        = 2 '<bos>'\n",
      "llm_load_print_meta: EOS token        = 1 '<eos>'\n",
      "llm_load_print_meta: UNK token        = 3 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<pad>'\n",
      "llm_load_print_meta: LF token         = 227 '<0x0A>'\n",
      "llm_load_print_meta: EOT token        = 107 '<end_of_turn>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: ggml ctx size =    0.41 MiB\n",
      "ggml_backend_metal_log_allocated_size: allocated buffer, size =  5488.42 MiB, ( 5488.50 / 12288.02)\n",
      "llm_load_tensors: offloading 42 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 43/43 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =   717.77 MiB\n",
      "llm_load_tensors:      Metal buffer size =  5488.41 MiB\n",
      "...............................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M3 Pro\n",
      "ggml_metal_init: picking default device: Apple M3 Pro\n",
      "ggml_metal_init: using embedded metal library\n",
      "ggml_metal_init: GPU name:   Apple M3 Pro\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple9  (1009)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction support   = true\n",
      "ggml_metal_init: simdgroup matrix mul. support = true\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 12884.92 MB\n",
      "llama_kv_cache_init:      Metal KV buffer size =   168.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  168.00 MiB, K (f16):   84.00 MiB, V (f16):   84.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.98 MiB\n",
      "llama_new_context_with_model:      Metal compute buffer size =   507.00 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =     9.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1690\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 0 | NEON = 1 | SVE = 0 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 0 | \n",
      "Model metadata: {'quantize.imatrix.entries_count': '294', 'quantize.imatrix.file': '/models_out/gemma-2-9b-it-GGUF/gemma-2-9b-it.imatrix', 'quantize.imatrix.chunks_count': '128', 'tokenizer.chat_template': \"{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\\n' + message['content'] | trim + '<end_of_turn>\\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\\n'}}{% endif %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.eos_token_id': '1', 'gemma2.attention.layer_norm_rms_epsilon': '0.000001', 'tokenizer.ggml.bos_token_id': '2', 'general.quantization_version': '2', 'gemma2.attention.value_length': '256', 'gemma2.attention.sliding_window': '4096', 'tokenizer.ggml.pre': 'default', 'tokenizer.ggml.unknown_token_id': '3', 'gemma2.final_logit_softcapping': '30.000000', 'general.file_type': '15', 'gemma2.attention.key_length': '256', 'gemma2.attention.head_count_kv': '8', 'tokenizer.ggml.model': 'llama', 'gemma2.feed_forward_length': '14336', 'gemma2.block_count': '42', 'tokenizer.ggml.add_space_prefix': 'false', 'general.architecture': 'gemma2', 'gemma2.embedding_length': '3584', 'gemma2.context_length': '8192', 'gemma2.attention.head_count': '16', 'gemma2.attn_logit_softcapping': '50.000000', 'quantize.imatrix.dataset': '/training_dir/calibration_datav3.txt', 'general.name': 'gemma-2-9b-it'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n",
      "' + message['content'] | trim + '<end_of_turn>\n",
      "' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n",
      "'}}{% endif %}\n",
      "Using chat eos_token: <eos>\n",
      "Using chat bos_token: <bos>\n",
      "\n",
      "llama_print_timings:        load time =    8946.94 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 10869.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8946.90 ms /     9 tokens (  994.10 ms per token,     1.01 tokens per second)\n",
      "llama_print_timings:        eval time =      49.49 ms /     1 runs   (   49.49 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:       total time =    8998.58 ms /    10 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:   Привет\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "# Укажите путь к скачанной модели\n",
    "model_path = \"gemma-2-9b-it-Q4_K_M.gguf\"\n",
    "\n",
    "# Загрузка модели с использованием CUDA\n",
    "model = Llama(\n",
    "    model_path,\n",
    "    n_gpu_layers=10000000,  # Укажите максимально возможное значение\n",
    "    n_batch=512,            # Увеличьте размер пакета\n",
    "    n_threads=4             # Уменьшите количество потоков\n",
    ")\n",
    "\n",
    "# Функция для генерации ответа с увеличенной длиной ответа\n",
    "def generate_response(context, max_tokens=50):\n",
    "    output = model(context, max_tokens=max_tokens)\n",
    "    response = output['choices'][0]['text']\n",
    "    return response\n",
    "\n",
    "# История сообщений\n",
    "history = []\n",
    "\n",
    "# Основной цикл чата\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "    history.append(f\"User: {user_input}\")\n",
    "    context = \"\\n\".join(history) + \"\\nBot:\"\n",
    "    response = generate_response(context, max_tokens=2)  # Увеличиваем длину ответа до 2048 токенов\n",
    "    print(f\"Bot: {response}\")\n",
    "    history.append(f\"Bot: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_stackoverflow.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 33 key-value pairs and 464 tensors from gemma-2-9b-it-Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = gemma2\n",
      "llama_model_loader: - kv   1:                               general.name str              = gemma-2-9b-it\n",
      "llama_model_loader: - kv   2:                      gemma2.context_length u32              = 8192\n",
      "llama_model_loader: - kv   3:                    gemma2.embedding_length u32              = 3584\n",
      "llama_model_loader: - kv   4:                         gemma2.block_count u32              = 42\n",
      "llama_model_loader: - kv   5:                 gemma2.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                gemma2.attention.head_count u32              = 16\n",
      "llama_model_loader: - kv   7:             gemma2.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   8:    gemma2.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv   9:                gemma2.attention.key_length u32              = 256\n",
      "llama_model_loader: - kv  10:              gemma2.attention.value_length u32              = 256\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:              gemma2.attn_logit_softcapping f32              = 50.000000\n",
      "llama_model_loader: - kv  13:             gemma2.final_logit_softcapping f32              = 30.000000\n",
      "llama_model_loader: - kv  14:            gemma2.attention.sliding_window u32              = 4096\n",
      "llama_model_loader: - kv  15:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  16:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.tokens arr[str,256000]  = [\"<pad>\", \"<eos>\", \"<bos>\", \"<unk>\", ...\n",
      "llama_model_loader: - kv  18:                      tokenizer.ggml.scores arr[f32,256000]  = [-1000.000000, -1000.000000, -1000.00...\n",
      "llama_model_loader: - kv  19:                  tokenizer.ggml.token_type arr[i32,256000]  = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\n",
      "llama_model_loader: - kv  20:                tokenizer.ggml.bos_token_id u32              = 2\n",
      "llama_model_loader: - kv  21:                tokenizer.ggml.eos_token_id u32              = 1\n",
      "llama_model_loader: - kv  22:            tokenizer.ggml.unknown_token_id u32              = 3\n",
      "llama_model_loader: - kv  23:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  24:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  25:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  26:                    tokenizer.chat_template str              = {{ bos_token }}{% if messages[0]['rol...\n",
      "llama_model_loader: - kv  27:            tokenizer.ggml.add_space_prefix bool             = false\n",
      "llama_model_loader: - kv  28:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  29:                      quantize.imatrix.file str              = /models_out/gemma-2-9b-it-GGUF/gemma-...\n",
      "llama_model_loader: - kv  30:                   quantize.imatrix.dataset str              = /training_dir/calibration_datav3.txt\n",
      "llama_model_loader: - kv  31:             quantize.imatrix.entries_count i32              = 294\n",
      "llama_model_loader: - kv  32:              quantize.imatrix.chunks_count i32              = 128\n",
      "llama_model_loader: - type  f32:  169 tensors\n",
      "llama_model_loader: - type q4_K:  252 tensors\n",
      "llama_model_loader: - type q6_K:   43 tensors\n",
      "llm_load_vocab: special tokens cache size = 217\n",
      "llm_load_vocab: token to piece cache size = 1.6014 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = gemma2\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 256000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 3584\n",
      "llm_load_print_meta: n_layer          = 42\n",
      "llm_load_print_meta: n_head           = 16\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 256\n",
      "llm_load_print_meta: n_swa            = 4096\n",
      "llm_load_print_meta: n_embd_head_k    = 256\n",
      "llm_load_print_meta: n_embd_head_v    = 256\n",
      "llm_load_print_meta: n_gqa            = 2\n",
      "llm_load_print_meta: n_embd_k_gqa     = 2048\n",
      "llm_load_print_meta: n_embd_v_gqa     = 2048\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 2\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 9B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 9.24 B\n",
      "llm_load_print_meta: model size       = 5.36 GiB (4.98 BPW) \n",
      "llm_load_print_meta: general.name     = gemma-2-9b-it\n",
      "llm_load_print_meta: BOS token        = 2 '<bos>'\n",
      "llm_load_print_meta: EOS token        = 1 '<eos>'\n",
      "llm_load_print_meta: UNK token        = 3 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<pad>'\n",
      "llm_load_print_meta: LF token         = 227 '<0x0A>'\n",
      "llm_load_print_meta: EOT token        = 107 '<end_of_turn>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: ggml ctx size =    0.21 MiB\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/43 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  5488.40 MiB\n",
      "...............................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   168.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  168.00 MiB, K (f16):   84.00 MiB, V (f16):   84.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.98 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   507.00 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1690\n",
      "llama_new_context_with_model: graph splits = 675\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 0 | NEON = 1 | SVE = 0 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 0 | \n",
      "Model metadata: {'quantize.imatrix.entries_count': '294', 'quantize.imatrix.file': '/models_out/gemma-2-9b-it-GGUF/gemma-2-9b-it.imatrix', 'quantize.imatrix.chunks_count': '128', 'tokenizer.chat_template': \"{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\\n' + message['content'] | trim + '<end_of_turn>\\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\\n'}}{% endif %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.eos_token_id': '1', 'gemma2.attention.layer_norm_rms_epsilon': '0.000001', 'tokenizer.ggml.bos_token_id': '2', 'general.quantization_version': '2', 'gemma2.attention.value_length': '256', 'gemma2.attention.sliding_window': '4096', 'tokenizer.ggml.pre': 'default', 'tokenizer.ggml.unknown_token_id': '3', 'gemma2.final_logit_softcapping': '30.000000', 'general.file_type': '15', 'gemma2.attention.key_length': '256', 'gemma2.attention.head_count_kv': '8', 'tokenizer.ggml.model': 'llama', 'gemma2.feed_forward_length': '14336', 'gemma2.block_count': '42', 'tokenizer.ggml.add_space_prefix': 'false', 'general.architecture': 'gemma2', 'gemma2.embedding_length': '3584', 'gemma2.context_length': '8192', 'gemma2.attention.head_count': '16', 'gemma2.attn_logit_softcapping': '50.000000', 'quantize.imatrix.dataset': '/training_dir/calibration_datav3.txt', 'general.name': 'gemma-2-9b-it'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n",
      "' + message['content'] | trim + '<end_of_turn>\n",
      "' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n",
      "'}}{% endif %}\n",
      "Using chat eos_token: <eos>\n",
      "Using chat bos_token: <bos>\n",
      "\n",
      "llama_print_timings:        load time =    4608.94 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 11049.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4608.85 ms /    99 tokens (   46.55 ms per token,    21.48 tokens per second)\n",
      "llama_print_timings:        eval time =     209.56 ms /     1 runs   (  209.56 ms per token,     4.77 tokens per second)\n",
      "llama_print_timings:       total time =    4820.44 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "959 а что ввели для вычислений? - а ничего -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4608.94 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 11111.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2997.50 ms /    81 tokens (   37.01 ms per token,    27.02 tokens per second)\n",
      "llama_print_timings:        eval time =      68.53 ms /     1 runs   (   68.53 ms per token,    14.59 tokens per second)\n",
      "llama_print_timings:       total time =    3067.55 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960 эм, как вы представляете себе принудительный обрыв выполнения кода? 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4608.94 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 11428.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3452.11 ms /   119 tokens (   29.01 ms per token,    34.47 tokens per second)\n",
      "llama_print_timings:        eval time =     135.07 ms /     1 runs   (  135.07 ms per token,     7.40 tokens per second)\n",
      "llama_print_timings:       total time =    3589.61 ms /   120 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "961 Никак, просто последующие участки будут тормозить, если тяжело, ничего против не имею. По сути, мне нужен аналог requestAnimationFrame, но с возможностью задать свое кол-во \"кадров\" в секунду и с высокой точностью. -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4608.94 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 11049.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3516.40 ms /   125 tokens (   28.13 ms per token,    35.55 tokens per second)\n",
      "llama_print_timings:        eval time =      84.53 ms /     1 runs   (   84.53 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:       total time =    3602.55 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "962 А ещё можно подумать над тем, нужно ли так сильно грузить браузер, выполняя тонны вычислений на JS. Возможно, вычисления можно оптимизировать. Или можно сделать отдельный клиент игры, вообще не ввязываясь в проблемы с JS и браузером. -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4608.94 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     2 runs   (    0.08 ms per token, 12048.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3442.72 ms /   100 tokens (   34.43 ms per token,    29.05 tokens per second)\n",
      "llama_print_timings:        eval time =     225.12 ms /     1 runs   (  225.12 ms per token,     4.44 tokens per second)\n",
      "llama_print_timings:       total time =    3671.34 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "963 @Regent это нынче не модно и не круто, сейчас в браузере принято делать ВСЁ ) Даже UT99 портировали на js -_- -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4608.94 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 11299.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4439.58 ms /   166 tokens (   26.74 ms per token,    37.39 tokens per second)\n",
      "llama_print_timings:        eval time =      77.75 ms /     1 runs   (   77.75 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:       total time =    4519.12 ms /   167 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "964 Еще лучше разобраться с идеей расщепления логики посредством функций вам поможет понимание работы функций в математике - вы можете не знать, как устроен синус, например, но \"швырнув\" в него аргумент вы получаете какой-то результат; или вы можете использовать некоторое имя \"f()\" для обозначения какой-нибудь очень сложной мат.функции, не дублируя каждый раз ее целиком. Примерно так же и в программировании. -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4608.94 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     2 runs   (    0.09 ms per token, 10582.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4752.83 ms /   169 tokens (   28.12 ms per token,    35.56 tokens per second)\n",
      "llama_print_timings:        eval time =     272.32 ms /     1 runs   (  272.32 ms per token,     3.67 tokens per second)\n",
      "llama_print_timings:       total time =    5028.49 ms /   170 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "965 +  DRY - don't repeat yourself - \"не повторяй себя\" или \"не повторяйся\". Гораздо удобнее написать имя функции нежели комбинацию из 10 и более команд в 30 различных точках основной программы. А если таких точек ещё больше, и параметры в них должны быть отличные друг от друга - то тут вообще без функций можно сойти с ума. Или упасть без сил после часов беспрерывного набора одного и того же кода с вариациями. -1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Классификация сообщений из колонки 'text'\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (\u001b[38;5;241m959\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df)):\n\u001b[0;32m---> 30\u001b[0m     new_label \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i, df\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m], new_label)\n\u001b[1;32m     32\u001b[0m     df\u001b[38;5;241m.\u001b[39miat[i, df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m)] \u001b[38;5;241m=\u001b[39m new_label\n",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m, in \u001b[0;36mclassify_message\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassify_message\u001b[39m(message):\n\u001b[1;32m     12\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mКлассифицируй сообщение на две метки 0 - нейтральное, 1 - негативное.:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Оброти внимание на сарказм, неуважительное общение, обращение по имени (без отчества), не деловое общение, оскорбление, насмешка, высмеивание, сообщения имеющие междометия эм, ха и т.д  Classification:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 13\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     classification \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/llama_cpp/llama.py:1789\u001b[0m, in \u001b[0;36mLlama.__call__\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1725\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1726\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1727\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     logit_bias: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1752\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[CreateCompletionResponse, Iterator[CreateCompletionStreamResponse]]:\n\u001b[1;32m   1753\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate text from a prompt.\u001b[39;00m\n\u001b[1;32m   1754\u001b[0m \n\u001b[1;32m   1755\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;124;03m        Response object containing the generated text.\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1789\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1790\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1795\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtypical_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypical_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1798\u001b[0m \u001b[43m        \u001b[49m\u001b[43mecho\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mecho\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1799\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1800\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1801\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1802\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepeat_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepeat_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1803\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1805\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1806\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtfs_z\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtfs_z\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1807\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmirostat_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1808\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmirostat_tau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_tau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1809\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmirostat_eta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_eta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1811\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1812\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1813\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrammar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1814\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1815\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/llama_cpp/llama.py:1722\u001b[0m, in \u001b[0;36mLlama.create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1720\u001b[0m     chunks: Iterator[CreateCompletionStreamResponse] \u001b[38;5;241m=\u001b[39m completion_or_chunks\n\u001b[1;32m   1721\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chunks\n\u001b[0;32m-> 1722\u001b[0m completion: Completion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcompletion_or_chunks\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m completion\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/llama_cpp/llama.py:1207\u001b[0m, in \u001b[0;36mLlama._create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1205\u001b[0m finish_reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1206\u001b[0m multibyte_fix \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m   1208\u001b[0m     prompt_tokens,\n\u001b[1;32m   1209\u001b[0m     top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[1;32m   1210\u001b[0m     top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[1;32m   1211\u001b[0m     min_p\u001b[38;5;241m=\u001b[39mmin_p,\n\u001b[1;32m   1212\u001b[0m     typical_p\u001b[38;5;241m=\u001b[39mtypical_p,\n\u001b[1;32m   1213\u001b[0m     temp\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[1;32m   1214\u001b[0m     tfs_z\u001b[38;5;241m=\u001b[39mtfs_z,\n\u001b[1;32m   1215\u001b[0m     mirostat_mode\u001b[38;5;241m=\u001b[39mmirostat_mode,\n\u001b[1;32m   1216\u001b[0m     mirostat_tau\u001b[38;5;241m=\u001b[39mmirostat_tau,\n\u001b[1;32m   1217\u001b[0m     mirostat_eta\u001b[38;5;241m=\u001b[39mmirostat_eta,\n\u001b[1;32m   1218\u001b[0m     frequency_penalty\u001b[38;5;241m=\u001b[39mfrequency_penalty,\n\u001b[1;32m   1219\u001b[0m     presence_penalty\u001b[38;5;241m=\u001b[39mpresence_penalty,\n\u001b[1;32m   1220\u001b[0m     repeat_penalty\u001b[38;5;241m=\u001b[39mrepeat_penalty,\n\u001b[1;32m   1221\u001b[0m     stopping_criteria\u001b[38;5;241m=\u001b[39mstopping_criteria,\n\u001b[1;32m   1222\u001b[0m     logits_processor\u001b[38;5;241m=\u001b[39mlogits_processor,\n\u001b[1;32m   1223\u001b[0m     grammar\u001b[38;5;241m=\u001b[39mgrammar,\n\u001b[1;32m   1224\u001b[0m ):\n\u001b[1;32m   1225\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1226\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m llama_cpp\u001b[38;5;241m.\u001b[39mllama_token_is_eog(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mmodel, token):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/llama_cpp/llama.py:799\u001b[0m, in \u001b[0;36mLlama.generate\u001b[0;34m(self, tokens, top_k, top_p, min_p, typical_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, penalize_nl, logits_processor, stopping_criteria, grammar)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;66;03m# Eval and sample\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 799\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m sample_idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_tokens:\n\u001b[1;32m    801\u001b[0m         token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample(\n\u001b[1;32m    802\u001b[0m             top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[1;32m    803\u001b[0m             top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    817\u001b[0m             idx\u001b[38;5;241m=\u001b[39msample_idx,\n\u001b[1;32m    818\u001b[0m         )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/llama_cpp/llama.py:633\u001b[0m, in \u001b[0;36mLlama.eval\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    629\u001b[0m n_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch)\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch\u001b[38;5;241m.\u001b[39mset_batch(\n\u001b[1;32m    631\u001b[0m     batch\u001b[38;5;241m=\u001b[39mbatch, n_past\u001b[38;5;241m=\u001b[39mn_past, logits_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_params\u001b[38;5;241m.\u001b[39mlogits_all\n\u001b[1;32m    632\u001b[0m )\n\u001b[0;32m--> 633\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;66;03m# Save tokens\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_ids[n_past : n_past \u001b[38;5;241m+\u001b[39m n_tokens] \u001b[38;5;241m=\u001b[39m batch\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/llama_cpp/_internals.py:357\u001b[0m, in \u001b[0;36m_LlamaContext.decode\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 357\u001b[0m return_code \u001b[38;5;241m=\u001b[39m \u001b[43mllama_cpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama_decode returned \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from llama_cpp import Llama\n",
    "\n",
    "# Укажите путь к скачанной модели\n",
    "model_path = \"gemma-2-9b-it-Q4_K_M.gguf\"\n",
    "\n",
    "# Загрузка модели\n",
    "model = Llama(model_path)\n",
    "\n",
    "# Функция для классификации сообщения\n",
    "def classify_message(message):\n",
    "    context = f\"Classify the message into two labels 0 - neutral, 1 - negative.:\\n{message}\\n Pay attention to sarcasm, disrespectful communication, first name (without patronymic), non-business communication, insult, ridicule, ridicule, messages with interjections em, ha, etc. Classification:\"\n",
    "    output = model(context, max_tokens=2)\n",
    "    classification = output['choices'][0]['text'].strip()\n",
    "\n",
    "    \n",
    "    try:\n",
    "        classification = int(classification)\n",
    "\n",
    "    except:\n",
    "        classification = - 1    \n",
    "\n",
    "    return classification\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('data_stackoverflow.csv')\n",
    "\n",
    "# Классификация сообщений из колонки 'text'\n",
    "for i in range (959, len(df)):\n",
    "    new_label = classify_message(df.iloc[i]['text'])\n",
    "    print(i, df.iloc[i]['text'], new_label)\n",
    "    df.iat[i, df.columns.get_loc('label')] = new_label\n",
    "# Сохранение результатов в новый CSV-файл\n",
    "data.to_csv('data_stackoverflow_classified.csv', index=False)\n",
    "\n",
    "# Вывод первых 5 строк с классификацией\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short = df[:1131]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                   text  label\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>     Ну, в стандарте такого нет, а вот что в этом &lt;<span style=\"color: #808000; text-decoration-color: #808000\">...</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>     @Harry этот оператор из С++<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>, насколько я помню.     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>     @Harry пишет \"превышение допустимой длины на <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>     @RiotBr3aker А! ну, я еще и С++<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> не очень выу<span style=\"color: #808000; text-decoration-color: #808000\">...</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>     Если у кого появится желание перевести: stacko<span style=\"color: #808000; text-decoration-color: #808000\">...</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                 <span style=\"color: #808000; text-decoration-color: #808000\">...</span>    <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1126</span>  static_cast делает только преобразование арифм<span style=\"color: #808000; text-decoration-color: #808000\">...</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1127</span>  @IAZ: частично: ideone.com/wkpEhT Спасибо, поп<span style=\"color: #808000; text-decoration-color: #808000\">...</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1128</span>  @VladD: static_cast для указателей работает \"п<span style=\"color: #808000; text-decoration-color: #808000\">...</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1129</span>  @avp: <span style=\"color: #008000; text-decoration-color: #008000\">\"не знаешь - не трогай\"</span> -- очень правиль<span style=\"color: #808000; text-decoration-color: #808000\">...</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1130</span>  Что-то я подозреваю, что пустая структура при <span style=\"color: #808000; text-decoration-color: #808000\">...</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "\n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1131</span> rows x <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> columns<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "\u001b[1;36m0\u001b[0m     Ну, в стандарте такого нет, а вот что в этом <\u001b[33m...\u001b[0m     \u001b[1;36m-1\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m     @Harry этот оператор из С++\u001b[1;36m20\u001b[0m, насколько я помню.     \u001b[1;36m-1\u001b[0m\n",
       "\u001b[1;36m2\u001b[0m     @Harry пишет \"превышение допустимой длины на \u001b[1;36m2\u001b[0m\u001b[33m...\u001b[0m      \u001b[1;36m2\u001b[0m\n",
       "\u001b[1;36m3\u001b[0m     @RiotBr3aker А! ну, я еще и С++\u001b[1;36m17\u001b[0m не очень выу\u001b[33m...\u001b[0m     \u001b[1;36m-1\u001b[0m\n",
       "\u001b[1;36m4\u001b[0m     Если у кого появится желание перевести: stacko\u001b[33m...\u001b[0m      \u001b[1;36m0\u001b[0m\n",
       "\u001b[33m...\u001b[0m                                                 \u001b[33m...\u001b[0m    \u001b[33m...\u001b[0m\n",
       "\u001b[1;36m1126\u001b[0m  static_cast делает только преобразование арифм\u001b[33m...\u001b[0m      \u001b[1;36m0\u001b[0m\n",
       "\u001b[1;36m1127\u001b[0m  @IAZ: частично: ideone.com/wkpEhT Спасибо, поп\u001b[33m...\u001b[0m      \u001b[1;36m1\u001b[0m\n",
       "\u001b[1;36m1128\u001b[0m  @VladD: static_cast для указателей работает \"п\u001b[33m...\u001b[0m      \u001b[1;36m2\u001b[0m\n",
       "\u001b[1;36m1129\u001b[0m  @avp: \u001b[32m\"не знаешь - не трогай\"\u001b[0m -- очень правиль\u001b[33m...\u001b[0m     \u001b[1;36m-1\u001b[0m\n",
       "\u001b[1;36m1130\u001b[0m  Что-то я подозреваю, что пустая структура при \u001b[33m...\u001b[0m      \u001b[1;36m1\u001b[0m\n",
       "\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m1131\u001b[0m rows x \u001b[1;36m2\u001b[0m columns\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                    text  label\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>      Ну, в стандарте такого нет, а вот что в этом &lt;<span style=\"color: #808000; text-decoration-color: #808000\">...</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>      @Harry этот оператор из С++<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>, насколько я помню.     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>      @Harry пишет \"превышение допустимой длины на <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>      @RiotBr3aker А! ну, я еще и С++<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> не очень выу<span style=\"color: #808000; text-decoration-color: #808000\">...</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>      Если у кого появится желание перевести: stacko<span style=\"color: #808000; text-decoration-color: #808000\">...</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>    <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46347</span>                                  Тоже правильно :<span style=\"font-weight: bold\">)</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46348</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Смысл использовать jquery только для провер<span style=\"color: #808000; text-decoration-color: #808000\">...</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46349</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. алерт только для того, чтобы программист са<span style=\"color: #808000; text-decoration-color: #808000\">...</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46350</span>  @Air вы действительно считаете, что этот пост <span style=\"color: #808000; text-decoration-color: #808000\">...</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46351</span>  @PashaPash, не так не считаю, это просто невни<span style=\"color: #808000; text-decoration-color: #808000\">...</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>\n",
       "\n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46352</span> rows x <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> columns<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "\u001b[1;36m0\u001b[0m      Ну, в стандарте такого нет, а вот что в этом <\u001b[33m...\u001b[0m      \u001b[1;36m3\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m      @Harry этот оператор из С++\u001b[1;36m20\u001b[0m, насколько я помню.     \u001b[1;36m-1\u001b[0m\n",
       "\u001b[1;36m2\u001b[0m      @Harry пишет \"превышение допустимой длины на \u001b[1;36m2\u001b[0m\u001b[33m...\u001b[0m      \u001b[1;36m2\u001b[0m\n",
       "\u001b[1;36m3\u001b[0m      @RiotBr3aker А! ну, я еще и С++\u001b[1;36m17\u001b[0m не очень выу\u001b[33m...\u001b[0m     \u001b[1;36m-1\u001b[0m\n",
       "\u001b[1;36m4\u001b[0m      Если у кого появится желание перевести: stacko\u001b[33m...\u001b[0m      \u001b[1;36m0\u001b[0m\n",
       "\u001b[33m...\u001b[0m                                                  \u001b[33m...\u001b[0m    \u001b[33m...\u001b[0m\n",
       "\u001b[1;36m46347\u001b[0m                                  Тоже правильно :\u001b[1m)\u001b[0m     \u001b[1;36m-1\u001b[0m\n",
       "\u001b[1;36m46348\u001b[0m  \u001b[1;36m1\u001b[0m. Смысл использовать jquery только для провер\u001b[33m...\u001b[0m     \u001b[1;36m-1\u001b[0m\n",
       "\u001b[1;36m46349\u001b[0m  \u001b[1;36m1\u001b[0m. алерт только для того, чтобы программист са\u001b[33m...\u001b[0m     \u001b[1;36m-1\u001b[0m\n",
       "\u001b[1;36m46350\u001b[0m  @Air вы действительно считаете, что этот пост \u001b[33m...\u001b[0m      \u001b[1;36m2\u001b[0m\n",
       "\u001b[1;36m46351\u001b[0m  @PashaPash, не так не считаю, это просто невни\u001b[33m...\u001b[0m     \u001b[1;36m-1\u001b[0m\n",
       "\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m46352\u001b[0m rows x \u001b[1;36m2\u001b[0m columns\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short = pd.read_csv('data_stackoverflow_short_gemma.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short = df_short[df_short['label'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                  text  label\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>    @Harry пишет \"превышение допустимой длины на <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>    Если у кого появится желание перевести: stacko<span style=\"color: #808000; text-decoration-color: #808000\">...</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>    Эм.. Это ж неправда<span style=\"color: #808000; text-decoration-color: #808000\">...</span> Даже про целочисленное <span style=\"color: #808000; text-decoration-color: #808000\">...</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>    Машинный перевод каждый может применить к ориг<span style=\"color: #808000; text-decoration-color: #808000\">...</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>    Ничего не понял из ответа. Линк на оригинал по<span style=\"color: #808000; text-decoration-color: #808000\">...</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "..                                                 <span style=\"color: #808000; text-decoration-color: #808000\">...</span>    <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">830</span>  Хороший ответ.  --  А ведь можно сказать и так<span style=\"color: #808000; text-decoration-color: #808000\">...</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">831</span>  static_cast делает только преобразование арифм<span style=\"color: #808000; text-decoration-color: #808000\">...</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">832</span>  @IAZ: частично: ideone.com/wkpEhT Спасибо, поп<span style=\"color: #808000; text-decoration-color: #808000\">...</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">833</span>  @VladD: static_cast для указателей работает \"п<span style=\"color: #808000; text-decoration-color: #808000\">...</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">834</span>  Что-то я подозреваю, что пустая структура при <span style=\"color: #808000; text-decoration-color: #808000\">...</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "\n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">835</span> rows x <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> columns<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "\u001b[1;36m0\u001b[0m    @Harry пишет \"превышение допустимой длины на \u001b[1;36m2\u001b[0m\u001b[33m...\u001b[0m      \u001b[1;36m2\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m    Если у кого появится желание перевести: stacko\u001b[33m...\u001b[0m      \u001b[1;36m0\u001b[0m\n",
       "\u001b[1;36m2\u001b[0m    Эм.. Это ж неправда\u001b[33m...\u001b[0m Даже про целочисленное \u001b[33m...\u001b[0m      \u001b[1;36m2\u001b[0m\n",
       "\u001b[1;36m3\u001b[0m    Машинный перевод каждый может применить к ориг\u001b[33m...\u001b[0m      \u001b[1;36m2\u001b[0m\n",
       "\u001b[1;36m4\u001b[0m    Ничего не понял из ответа. Линк на оригинал по\u001b[33m...\u001b[0m      \u001b[1;36m2\u001b[0m\n",
       "..                                                 \u001b[33m...\u001b[0m    \u001b[33m...\u001b[0m\n",
       "\u001b[1;36m830\u001b[0m  Хороший ответ.  --  А ведь можно сказать и так\u001b[33m...\u001b[0m      \u001b[1;36m2\u001b[0m\n",
       "\u001b[1;36m831\u001b[0m  static_cast делает только преобразование арифм\u001b[33m...\u001b[0m      \u001b[1;36m0\u001b[0m\n",
       "\u001b[1;36m832\u001b[0m  @IAZ: частично: ideone.com/wkpEhT Спасибо, поп\u001b[33m...\u001b[0m      \u001b[1;36m1\u001b[0m\n",
       "\u001b[1;36m833\u001b[0m  @VladD: static_cast для указателей работает \"п\u001b[33m...\u001b[0m      \u001b[1;36m2\u001b[0m\n",
       "\u001b[1;36m834\u001b[0m  Что-то я подозреваю, что пустая структура при \u001b[33m...\u001b[0m      \u001b[1;36m1\u001b[0m\n",
       "\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m835\u001b[0m rows x \u001b[1;36m2\u001b[0m columns\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df_short)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
